"""
íˆ¬ìž ì‹œê·¸ë„ ëŒ€ì‹œë³´ë“œ API
Investment Signal Dashboard API
"""

import sys
import os
import json
import re
from datetime import datetime, timedelta
from typing import List, Dict, Optional
from pathlib import Path
from loguru import logger

sys.path.append('..')
from database.supabase_client import SupabaseClient


class SignalAPI:
    """íˆ¬ìž ì‹œê·¸ë„ API"""

    def __init__(self):
        try:
            self.db = SupabaseClient()
        except Exception as e:
            logger.warning(f"Supabase client initialization failed: {e}. Article features will still work.")
            self.db = None

        self.articles_dir = os.path.join(os.path.dirname(__file__), '..', 'articles')
        logger.info("Signal API initialized")

    def _extract_article_metadata(self, content: str) -> Dict:
        """ê¸°ì‚¬ ë‚´ìš©ì—ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
        metadata = {
            'title': '',
            'summary': '',
            'symbol': '',
            'timestamp': datetime.now().isoformat()
        }

        # TITLE ì¶”ì¶œ
        title_match = re.search(r'TITLE:\s*(.+?)(?:\n|$)', content)
        if title_match:
            metadata['title'] = title_match.group(1).strip()

        # í•µì‹¬ ìš”ì•½ ì¶”ì¶œ
        summary_match = re.search(r'## ðŸ“Œ í•µì‹¬ ìš”ì•½\s*\n\n(.*?)\n\n---', content, re.DOTALL)
        if summary_match:
            summary_text = summary_match.group(1)
            # ì²« 300ìžë§Œ ì¶”ì¶œ
            metadata['summary'] = summary_text.replace('\n', ' ')[:300]

        # ì‹¬ë³¼ ì¶”ì¶œ (íŒŒì¼ëª…ì—ì„œ)
        return metadata

    def _get_article_score(self, filename: str) -> Dict:
        """validation_report.jsonì—ì„œ ê¸°ì‚¬ ì ìˆ˜ ì¡°íšŒ"""
        try:
            report_path = os.path.join(os.path.dirname(__file__), '..', 'validation_report.json')
            if os.path.exists(report_path):
                with open(report_path, 'r', encoding='utf-8') as f:
                    report = json.load(f)
                    for result in report.get('results', []):
                        if result.get('file') == filename:
                            return {
                                'score': result.get('score', 0),
                                'completion_rate': result.get('completion_rate', '0%'),
                                'sections_passed': result.get('sections_passed', 0),
                                'total_sections': result.get('total_sections', 0)
                            }
        except Exception as e:
            logger.error(f"Error reading validation report: {e}")

        return {'score': 0, 'completion_rate': '0%', 'sections_passed': 0, 'total_sections': 0}

    def get_signals_by_level(
        self,
        level: int,
        hours: int = 24,
        limit: int = 50
    ) -> List[Dict]:
        """ë ˆë²¨ë³„ ì‹œê·¸ë„ ì¡°íšŒ

        Args:
            level: ì‹ í˜¸ ë ˆë²¨ (1-4)
            hours: ìµœê·¼ Nì‹œê°„ ë°ì´í„°
            limit: ìµœëŒ€ ê°œìˆ˜

        Returns:
            ì‹ í˜¸ ë¦¬ìŠ¤íŠ¸
        """
        try:
            if self.db is None:
                logger.warning("Supabase client not available")
                return []

            # Supabase ì¿¼ë¦¬ë¡œ ë°ì´í„° ì¡°íšŒ
            # ì‹¤ì œ êµ¬í˜„ì€ database ì—°ê²°ì— ë”°ë¼ ìˆ˜ì • í•„ìš”
            signals = self.db.get_signals_by_level(level, hours=hours, limit=limit)
            logger.info(f"Fetched {len(signals)} Level {level} signals")
            return signals

        except Exception as e:
            logger.error(f"Error fetching signals by level: {e}")
            return []

    def get_urgent_signals(self, hours: int = 24, limit: int = 20) -> List[Dict]:
        """ê¸´ê¸‰ ì‹œê·¸ë„ (Level 1) ì¡°íšŒ"""
        return self.get_signals_by_level(1, hours=hours, limit=limit)

    def get_high_priority_signals(self, hours: int = 24, limit: int = 30) -> List[Dict]:
        """ë†’ì€ ìš°ì„ ìˆœìœ„ ì‹œê·¸ë„ (Level 1-2) ì¡°íšŒ"""
        signals = []
        signals.extend(self.get_signals_by_level(1, hours=hours, limit=limit))
        signals.extend(self.get_signals_by_level(2, hours=hours, limit=limit))
        return signals

    def get_signals_by_symbol(
        self,
        symbol: str,
        hours: int = 24,
        limit: int = 20
    ) -> List[Dict]:
        """ì¢…ëª©ë³„ ì‹œê·¸ë„ ì¡°íšŒ"""
        try:
            if self.db is None:
                return []
            signals = self.db.get_signals_by_symbol(symbol, hours=hours, limit=limit)
            logger.info(f"Fetched {len(signals)} signals for {symbol}")
            return signals

        except Exception as e:
            logger.error(f"Error fetching signals for {symbol}: {e}")
            return []

    def get_trending_symbols(self, hours: int = 24, limit: int = 15) -> List[Dict]:
        """íŠ¸ë Œë”© ì¢…ëª© ì¡°íšŒ (ê°€ìž¥ ë§Žì€ ì‹œê·¸ë„ ë‚˜ì˜¨ ì¢…ëª©)"""
        try:
            if self.db is None:
                return []
            symbols = self.db.get_trending_symbols(hours=hours, limit=limit)
            logger.info(f"Fetched {len(symbols)} trending symbols")
            return symbols

        except Exception as e:
            logger.error(f"Error fetching trending symbols: {e}")
            return []

    def get_dashboard_summary(self, hours: int = 24) -> Dict:
        """ëŒ€ì‹œë³´ë“œ ìš”ì•½ ì •ë³´"""
        try:
            return {
                "timestamp": datetime.now().isoformat(),
                "period_hours": hours,
                "urgent_count": len(self.get_signals_by_level(1, hours=hours)),
                "high_count": len(self.get_signals_by_level(2, hours=hours)),
                "medium_count": len(self.get_signals_by_level(3, hours=hours)),
                "low_count": len(self.get_signals_by_level(4, hours=hours)),
                "trending_symbols": self.get_trending_symbols(hours=hours, limit=10),
                "latest_signals": self.get_signals_by_level(1, hours=hours, limit=5)
            }

        except Exception as e:
            logger.error(f"Error generating dashboard summary: {e}")
            return {"timestamp": datetime.now().isoformat(), "period_hours": hours, "urgent_count": 0, "high_count": 0, "medium_count": 0, "low_count": 0, "trending_symbols": [], "latest_signals": []}

    def get_price_impact_summary(self, hours: int = 24) -> Dict:
        """ê°€ê²© ì˜í–¥ ìš”ì•½"""
        try:
            if self.db is None:
                return {"up": 0, "down": 0, "neutral": 0}
            # ì–‘ìˆ˜/ìŒìˆ˜/ì¤‘ë¦½ ì‹œê·¸ë„ ë¹„ìœ¨ ê³„ì‚°
            return self.db.get_price_impact_summary(hours=hours)

        except Exception as e:
            logger.error(f"Error getting price impact summary: {e}")
            return {"up": 0, "down": 0, "neutral": 0}

    def get_important_symbols_today(self) -> List[Dict]:
        """ì˜¤ëŠ˜ ì£¼ëª©í•  ì¢…ëª©"""
        try:
            if self.db is None:
                return []
            return self.db.get_important_symbols_today()

        except Exception as e:
            logger.error(f"Error getting important symbols: {e}")
            return []

    def mark_signal_as_processed(self, signal_id: str) -> bool:
        """ì‹œê·¸ë„ì„ ì²˜ë¦¬ë¨ìœ¼ë¡œ í‘œì‹œ"""
        try:
            if self.db is None:
                return False
            # ì´ ê¸°ëŠ¥ì€ ë¸”ë¡œê±° íì—ì„œ ì„ íƒí•œ ì‹œê·¸ë„ì„ í‘œì‹œ
            return self.db.mark_signal_as_processed(signal_id)

        except Exception as e:
            logger.error(f"Error marking signal as processed: {e}")
            return False

    def get_signals_for_article(
        self,
        tier: str = "tier_1",
        hours: int = 24
    ) -> List[Dict]:
        """ê¸€ ìž‘ì„±ìš© ì‹œê·¸ë„ ì¡°íšŒ"""
        try:
            if self.db is None:
                return []

            if tier == "tier_1":
                # ê¸´ê¸‰ + ë†’ìŒ ì‹œê·¸ë„ë§Œ
                signals = self.get_signals_by_level(1, hours=hours, limit=30)
                signals.extend(self.get_signals_by_level(2, hours=hours, limit=20))
            elif tier == "tier_2":
                # ë†’ìŒ + ì¤‘ê°„ ì‹œê·¸ë„
                signals = self.get_signals_by_level(2, hours=hours, limit=30)
                signals.extend(self.get_signals_by_level(3, hours=hours, limit=20))
            else:  # tier_3
                # ëª¨ë“  ì‹œê·¸ë„
                signals = []
                for level in [1, 2, 3, 4]:
                    signals.extend(self.get_signals_by_level(level, hours=hours*7, limit=50))

            return signals

        except Exception as e:
            logger.error(f"Error getting signals for article: {e}")
            return []

    def get_all_articles(self) -> List[Dict]:
        """ìƒì„±ëœ ëª¨ë“  ê¸°ì‚¬ ì¡°íšŒ"""
        articles = []

        if not os.path.exists(self.articles_dir):
            logger.warning(f"Articles directory not found: {self.articles_dir}")
            return articles

        try:
            article_files = sorted(Path(self.articles_dir).glob('article_*.md'))

            for article_file in article_files:
                try:
                    with open(article_file, 'r', encoding='utf-8') as f:
                        content = f.read()

                    # ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
                    metadata = self._extract_article_metadata(content)

                    # ì ìˆ˜ ì¡°íšŒ
                    score_info = self._get_article_score(article_file.name)

                    # íŒŒì¼ëª…ì—ì„œ ì‹¬ë³¼ ì¶”ì¶œ
                    symbol_match = re.search(r'article_([A-Z]+)_', article_file.name)
                    symbol = symbol_match.group(1) if symbol_match else 'UNKNOWN'

                    article = {
                        'filename': article_file.name,
                        'symbol': symbol,
                        'title': metadata['title'],
                        'summary': metadata['summary'],
                        'score': score_info['score'],
                        'completion_rate': score_info['completion_rate'],
                        'sections_passed': score_info['sections_passed'],
                        'total_sections': score_info['total_sections'],
                        'created_date': datetime.fromtimestamp(article_file.stat().st_mtime).isoformat(),
                        'content_length': len(content),
                        'word_count': len(content.split())
                    }

                    articles.append(article)

                except Exception as e:
                    logger.error(f"Error processing article {article_file.name}: {e}")

            logger.info(f"Loaded {len(articles)} articles")
            return articles

        except Exception as e:
            logger.error(f"Error loading articles: {e}")
            return articles

    def get_article_by_symbol(self, symbol: str) -> Optional[Dict]:
        """ì‹¬ë³¼ë³„ ê¸°ì‚¬ ì¡°íšŒ"""
        try:
            articles = self.get_all_articles()
            for article in articles:
                if article['symbol'].upper() == symbol.upper():
                    # ì „ì²´ ë‚´ìš© ë¡œë“œ
                    article_path = os.path.join(self.articles_dir, article['filename'])
                    with open(article_path, 'r', encoding='utf-8') as f:
                        article['full_content'] = f.read()
                    return article

            return None

        except Exception as e:
            logger.error(f"Error getting article for {symbol}: {e}")
            return None

    def get_articles_stats(self) -> Dict:
        """ê¸°ì‚¬ í†µê³„"""
        try:
            articles = self.get_all_articles()

            if not articles:
                return {
                    'total': 0,
                    'average_score': 0,
                    'high_quality': 0,
                    'symbols': []
                }

            scores = [a['score'] for a in articles]
            average_score = sum(scores) / len(scores) if scores else 0
            high_quality = len([a for a in articles if a['score'] >= 90])

            symbols = sorted(set([a['symbol'] for a in articles]))

            return {
                'total': len(articles),
                'average_score': round(average_score, 1),
                'high_quality': high_quality,
                'symbols': symbols,
                'total_words': sum([a['word_count'] for a in articles])
            }

        except Exception as e:
            logger.error(f"Error calculating article stats: {e}")
            return {'total': 0, 'average_score': 0, 'high_quality': 0, 'symbols': []}
