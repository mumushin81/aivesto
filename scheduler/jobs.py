import schedule
import time
from datetime import datetime
from loguru import logger
import sys
import os

sys.path.append('..')
from database.supabase_client import SupabaseClient
from collectors import FinnhubCollector, AlphaVantageCollector, RSSCollector
from analyzers import AnalysisPipeline
from writers import ArticleGenerator
from dashboard import SignalAPI
from alerts import EmailAlertService
from alerts.telegram_alerts import TelegramAlertService
from blogger import ArticleQueueManager
from config.settings import (
    NEWS_COLLECTION_INTERVAL,
    ANALYSIS_INTERVAL,
    ARTICLE_GENERATION_INTERVAL
)

class JobScheduler:
    """ì‘ì—… ìŠ¤ì¼€ì¤„ëŸ¬"""

    def __init__(self):
        self.db = SupabaseClient()
        self.collectors = [
            FinnhubCollector(self.db),
            AlphaVantageCollector(self.db),
            RSSCollector(self.db)
        ]
        self.analyzer = AnalysisPipeline(self.db)
        self.writer = ArticleGenerator(self.db)

        # ì‹ í˜¸ ëŒ€ì‹œë³´ë“œ ì´ˆê¸°í™” (í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ ë¶„ì„)
        self.signal_api = SignalAPI()
        self.email_service = EmailAlertService()
        self.telegram_service = TelegramAlertService()
        self.queue_manager = ArticleQueueManager()

        # ì•Œë¦¼ ìˆ˜ì‹ ì (í™˜ê²½ ë³€ìˆ˜ì—ì„œ ë¡œë“œ)
        self.alert_recipients = os.getenv("ALERT_RECIPIENTS", "").split(",") if os.getenv("ALERT_RECIPIENTS") else []
        self.telegram_chat_ids = os.getenv("TELEGRAM_CHAT_IDS", "").split(",") if os.getenv("TELEGRAM_CHAT_IDS") else []

        logger.info("Job scheduler initialized (Claude Code + Local Analysis Mode)")
        if self.telegram_chat_ids:
            logger.info(f"âœ… Telegram alerts enabled for {len(self.telegram_chat_ids)} chat(s)")

    def collect_news_job(self):
        """ë‰´ìŠ¤ ìˆ˜ì§‘ ì‘ì—…"""
        logger.info("=== Starting news collection job ===")

        total_collected = 0
        for collector in self.collectors:
            try:
                count = collector.collect_and_save()
                total_collected += count
            except Exception as e:
                logger.error(f"Collector error: {e}")

        logger.info(f"=== News collection completed: {total_collected} items ===")

    def analyze_news_job(self):
        """ë‰´ìŠ¤ ë¶„ì„ ì‘ì—… (ìë™ ë¶„ì„ - ëª¨ë“  ë¯¸ë¶„ì„ ë‰´ìŠ¤)"""
        logger.info("=== Starting news analysis job (AUTO MODE) ===")

        try:
            # ìë™ ë¶„ì„: ë¯¸ë¶„ì„ ë‰´ìŠ¤ ëª¨ë‘ ë¶„ì„ (200ê°œì”© ë°°ì¹˜)
            analyzed_count = self.analyzer.run_analysis(limit=200)
            logger.info(f"=== Analysis completed: {analyzed_count} items ===")
        except Exception as e:
            logger.error(f"Analysis job error: {e}")

    def generate_articles_job(self, tier: str = "tier_1"):
        """ë¸”ë¡œê·¸ ê¸€ ìƒì„± ì‘ì—…"""
        logger.info("=== Starting article generation job ===")

        try:
            article_ids = self.writer.generate_daily_articles(tier=tier)
            logger.info(f"=== Article generation completed: {len(article_ids)} articles (Tier: {tier}) ===")
        except Exception as e:
            logger.error(f"Article generation job error: {e}")

    def cleanup_job(self):
        """ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬ ì‘ì—…"""
        logger.info("=== Starting cleanup job ===")

        try:
            self.db.cleanup_old_news()
            logger.info("=== Cleanup completed ===")
        except Exception as e:
            logger.error(f"Cleanup job error: {e}")

    def check_analysis_prompts_job(self):
        """ğŸ“ ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ í™•ì¸"""
        logger.info("=== Checking analysis prompts ===")

        try:
            from pathlib import Path
            prompts_dir = Path("prompts/analysis")
            results_dir = Path("prompts/results")

            if prompts_dir.exists():
                prompts = list(prompts_dir.glob("*.md"))
                results = list(results_dir.glob("*.json")) if results_dir.exists() else []

                pending = len(prompts) - len(results)

                if pending > 0:
                    logger.info(f"ğŸ“ Pending analysis: {pending} prompts waiting for Claude Code")
                    logger.info(f"   Generated: {len(prompts)} | Processed: {len(results)}")
                else:
                    logger.info(f"âœ… All prompts processed ({len(results)} completed)")

        except Exception as e:
            logger.error(f"Check prompts job error: {e}")

    def send_daily_digest_job(self):
        """ì¼ì¼ ìš”ì•½ ì´ë©”ì¼ & í…”ë ˆê·¸ë¨ ë°œì†¡"""
        logger.info("=== Starting daily digest job ===")

        email_sent = False
        telegram_sent = False

        # ì´ë©”ì¼ ë°œì†¡
        if self.alert_recipients:
            try:
                email_sent = self.email_service.send_daily_digest(self.alert_recipients, hours=24)
                if email_sent:
                    logger.info("âœ… Daily digest email sent successfully")
                else:
                    logger.warning("âš ï¸ Failed to send daily digest email")
            except Exception as e:
                logger.error(f"Email digest job error: {e}")
        else:
            logger.debug("No email recipients configured")

        # í…”ë ˆê·¸ë¨ ë°œì†¡
        if self.telegram_chat_ids:
            try:
                telegram_sent = self.telegram_service.send_daily_digest(self.telegram_chat_ids, hours=24)
                if telegram_sent:
                    logger.info("âœ… Daily digest Telegram sent successfully")
                else:
                    logger.warning("âš ï¸ Failed to send daily digest Telegram")
            except Exception as e:
                logger.error(f"Telegram digest job error: {e}")
        else:
            logger.debug("No Telegram chat IDs configured")

        if email_sent or telegram_sent:
            logger.info("=== Daily digest job completed ===")
        else:
            logger.warning("=== No digest sent (no recipients configured) ===")

    def send_blog_recommendations_job(self):
        """ë¸”ë¡œê±° ê¸€ì“°ê¸° ì¶”ì²œ ì—…ë°ì´íŠ¸"""
        logger.info("=== Starting blog recommendations job ===")

        try:
            recommendations = self.queue_manager.get_smart_recommendations()

            if recommendations:
                logger.info(f"=== Generated blog recommendations ===")
                logger.info(f"   Tier 1 Urgent: {len(recommendations.get('tier_1_urgent', []))} signals")
                logger.info(f"   Daily Suggestions: {len(recommendations.get('daily_suggestions', []))} items")
                logger.info(f"   Trending Symbols: {len(recommendations.get('trending_symbols', []))} symbols")

        except Exception as e:
            logger.error(f"Blog recommendations job error: {e}")

    def setup_schedule(self):
        """ìŠ¤ì¼€ì¤„ ì„¤ì •"""
        # ë‰´ìŠ¤ ìˆ˜ì§‘: 15ë¶„ë§ˆë‹¤
        schedule.every(NEWS_COLLECTION_INTERVAL // 60).minutes.do(self.collect_news_job)

        # ë‰´ìŠ¤ ë¶„ì„: 30ë¶„ë§ˆë‹¤
        schedule.every(ANALYSIS_INTERVAL // 60).minutes.do(self.analyze_news_job)

        # ë¶„ì„ í”„ë¡¬í”„íŠ¸ í™•ì¸: 1ì‹œê°„ë§ˆë‹¤ (Claude Code ì²˜ë¦¬ ìƒí™© í™•ì¸)
        schedule.every(60).minutes.do(self.check_analysis_prompts_job)

        # ë¸”ë¡œê·¸ ì¶”ì²œ: 1ì‹œê°„ë§ˆë‹¤
        schedule.every(ARTICLE_GENERATION_INTERVAL // 60).minutes.do(self.send_blog_recommendations_job)

        # ë¸”ë¡œê·¸ ê¸€ ìƒì„±: 2ì‹œê°„ë§ˆë‹¤
        schedule.every(ARTICLE_GENERATION_INTERVAL // 60).minutes.do(self.generate_articles_job)

        # ì¼ì¼ ìš”ì•½: ë§¤ì¼ ì˜¤ì „ 9ì‹œ
        schedule.every().day.at("09:00").do(self.send_daily_digest_job)

        # ë°ì´í„° ì •ë¦¬: ë§¤ì¼ ìƒˆë²½ 3ì‹œ
        schedule.every().day.at("03:00").do(self.cleanup_job)

        logger.info("Schedule configured (Claude Code + Local Mode):")
        logger.info(f"  - News collection: every {NEWS_COLLECTION_INTERVAL // 60} minutes")
        logger.info(f"  - News analysis (prompt generation): every {ANALYSIS_INTERVAL // 60} minutes")
        logger.info(f"  - Check prompts status: every 60 minutes")
        logger.info(f"  - Blog recommendations: every {ARTICLE_GENERATION_INTERVAL // 60} minutes")
        logger.info(f"  - Article generation (prompt): every {ARTICLE_GENERATION_INTERVAL // 60} minutes")
        logger.info(f"  - Daily digest: daily at 09:00")
        logger.info(f"  - Cleanup: daily at 03:00")
        logger.info("")
        logger.info("ğŸ’¡ Workflow:")
        logger.info("   1. System generates prompts (automatic)")
        logger.info("   2. Claude Code analyzes & writes (manual)")
        logger.info("   3. Results saved to database (manual)")
        logger.info("   4. Dashboard updates (automatic)")

    def run_once(self):
        """ëª¨ë“  ì‘ì—…ì„ í•œ ë²ˆ ì‹¤í–‰ (í…ŒìŠ¤íŠ¸ìš©)"""
        logger.info("=== Running all jobs once ===")

        self.collect_news_job()
        time.sleep(5)

        self.analyze_news_job()
        time.sleep(5)

        self.check_analysis_prompts_job()
        time.sleep(5)

        self.send_blog_recommendations_job()
        time.sleep(5)

        self.generate_articles_job()
        time.sleep(5)

        self.cleanup_job()

        logger.info("=== All jobs completed ===")

    def run_forever(self):
        """ìŠ¤ì¼€ì¤„ëŸ¬ ë¬´í•œ ì‹¤í–‰"""
        self.setup_schedule()

        # ì‹œì‘ ì‹œ í•œ ë²ˆ ì‹¤í–‰
        logger.info("Running initial job cycle...")
        self.run_once()

        # ë¬´í•œ ë£¨í”„
        logger.info("Starting scheduler loop...")
        while True:
            try:
                schedule.run_pending()
                time.sleep(60)  # 1ë¶„ë§ˆë‹¤ ì²´í¬
            except KeyboardInterrupt:
                logger.info("Scheduler stopped by user")
                break
            except Exception as e:
                logger.error(f"Scheduler error: {e}")
                time.sleep(60)
