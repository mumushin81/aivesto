#!/usr/bin/env python3
"""
Layer 1 ìˆ˜ì§‘ê¸° í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
Bloomberg, Reuters, WSJ RSS í”¼ë“œ í…ŒìŠ¤íŠ¸
"""
from collectors.bloomberg_collector import BloombergCollector
from collectors.reuters_collector import ReutersCollector
from collectors.wsj_collector import WSJCollector
from database.supabase_client import SupabaseClient
from loguru import logger

def test_collectors():
    """Layer 1 ìˆ˜ì§‘ê¸° í…ŒìŠ¤íŠ¸"""

    logger.info("="*60)
    logger.info("Layer 1 Collectors Test")
    logger.info("="*60)

    try:
        # Supabase í´ë¼ì´ì–¸íŠ¸ (ì‹¤íŒ¨í•´ë„ ê´œì°®ìŒ)
        try:
            db = SupabaseClient()
            logger.info("âœ… Supabase connected")
        except:
            db = None
            logger.warning("âš ï¸  Supabase not available, testing RSS only")

        # Bloomberg í…ŒìŠ¤íŠ¸
        logger.info("\nğŸ“° Testing Bloomberg Collector...")
        bloomberg = BloombergCollector(db)
        bloomberg_news = bloomberg.fetch_news()
        logger.info(f"   Collected: {len(bloomberg_news)} articles")

        if bloomberg_news:
            sample = bloomberg_news[0]
            logger.info(f"   Sample: {sample.title[:80]}")
            logger.info(f"   URL: {sample.url}")

        # Reuters í…ŒìŠ¤íŠ¸
        logger.info("\nğŸ“° Testing Reuters Collector...")
        reuters = ReutersCollector(db)
        reuters_news = reuters.fetch_news()
        logger.info(f"   Collected: {len(reuters_news)} articles")

        if reuters_news:
            sample = reuters_news[0]
            logger.info(f"   Sample: {sample.title[:80]}")
            logger.info(f"   URL: {sample.url}")

        # WSJ í…ŒìŠ¤íŠ¸
        logger.info("\nğŸ“° Testing WSJ Collector...")
        wsj = WSJCollector(db)
        wsj_news = wsj.fetch_news()
        logger.info(f"   Collected: {len(wsj_news)} articles")

        if wsj_news:
            sample = wsj_news[0]
            logger.info(f"   Sample: {sample.title[:80]}")
            logger.info(f"   URL: {sample.url}")

        # ìš”ì•½
        total = len(bloomberg_news) + len(reuters_news) + len(wsj_news)
        logger.info("\n"+"="*60)
        logger.info(f"âœ… Total Layer 1 articles collected: {total}")
        logger.info(f"   Bloomberg: {len(bloomberg_news)}")
        logger.info(f"   Reuters: {len(reuters_news)}")
        logger.info(f"   WSJ: {len(wsj_news)}")
        logger.info("="*60)

    except Exception as e:
        logger.error(f"âŒ Test failed: {e}")
        raise

if __name__ == "__main__":
    test_collectors()
