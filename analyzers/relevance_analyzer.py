from typing import Dict, List, Tuple
import json
from loguru import logger
import sys
from datetime import datetime
from pathlib import Path

sys.path.append('..')
from config.settings import MIN_RELEVANCE_SCORE
from database.models import AnalyzedNews, PriceImpact, Importance

class RelevanceAnalyzer:
    """ë‰´ìŠ¤ ê´€ë ¨ì„± ë¶„ì„ (í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ - Claude Code ì‚¬ìš©)"""

    def __init__(self):
        self.prompts_dir = Path("prompts/analysis")
        self.results_dir = Path("prompts/results")
        self.prompts_dir.mkdir(parents=True, exist_ok=True)
        self.results_dir.mkdir(parents=True, exist_ok=True)

        logger.info("Relevance analyzer initialized (Prompt-based mode - Claude Code)")

    def analyze_news(self, news_data: Dict) -> Dict:
        """ë‰´ìŠ¤ ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„± (ìˆ˜ë™ ë¶„ì„ìš©)"""
        try:
            title = news_data.get('title', '')
            content = news_data.get('content', '')
            existing_symbols = news_data.get('symbols', [])
            news_id = news_data.get('id', 'unknown')

            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self._build_analysis_prompt(title, content, existing_symbols)

            # í”„ë¡¬í”„íŠ¸ íŒŒì¼ ì €ì¥
            prompt_file = self._save_prompt(news_id, prompt)
            logger.info(f"ğŸ“ ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„±: {prompt_file}")
            logger.info(f"   ë‰´ìŠ¤: {title[:60]}")
            logger.info(f"   â†’ Claude Codeì—ì„œ ë‹¤ìŒì„ ì‹¤í–‰í•˜ì„¸ìš”:")
            logger.info(f"   cat {prompt_file}")

            return None  # ìˆ˜ë™ ë¶„ì„ì´ë¯€ë¡œ None ë°˜í™˜

        except Exception as e:
            logger.error(f"Error generating analysis prompt: {e}")
            return None

    def load_manual_analysis(self, json_response: str) -> Dict:
        """Claude Codeì—ì„œ ìˆ˜ë™ìœ¼ë¡œ ë¶„ì„í•œ JSON ê²°ê³¼ ë¡œë“œ"""
        try:
            result = self._parse_response(json_response)
            return result
        except Exception as e:
            logger.error(f"Error loading manual analysis: {e}")
            return None

    def _save_prompt(self, news_id: str, prompt: str) -> str:
        """í”„ë¡¬í”„íŠ¸ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{self.prompts_dir}/analysis_{news_id}_{timestamp}.md"

        with open(filename, 'w', encoding='utf-8') as f:
            f.write(prompt)

        return filename

    def _build_analysis_prompt(self, title: str, content: str, existing_symbols: List[str]) -> str:
        """Claudeì—ê²Œ ë³´ë‚¼ í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""
        return f"""ë‹¹ì‹ ì€ ë¯¸êµ­ ì£¼ì‹ ì‹œì¥ ì „ë¬¸ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ë‹¤ìŒ ë‰´ìŠ¤ë¥¼ ë¶„ì„í•˜ì—¬ ì£¼ì‹ íˆ¬ììì—ê²Œ ì–¼ë§ˆë‚˜ ìœ ìš©í•œì§€ í‰ê°€í•´ì£¼ì„¸ìš”.

ë‰´ìŠ¤ ì œëª©: {title}

ë‰´ìŠ¤ ë‚´ìš©:
{content[:2000]}

ê¸°ì¡´ ì¶”ì¶œëœ ì‹¬ë³¼: {', '.join(existing_symbols) if existing_symbols else 'ì—†ìŒ'}

ë‹¤ìŒ í•­ëª©ì„ JSON í˜•ì‹ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:

1. relevance_score (0-100): ì£¼ì‹ íˆ¬ììì—ê²Œ ì–¼ë§ˆë‚˜ ê´€ë ¨ì„±ì´ ë†’ì€ì§€
   - 0-30: ë¬´ê´€í•œ ë‰´ìŠ¤ (ì¼ë°˜ ë‰´ìŠ¤, ì •ì¹˜, ìŠ¤í¬ì¸  ë“±)
   - 31-60: ê°„ì ‘ ê´€ë ¨ (ê²½ì œ ì¼ë°˜, ì—…ê³„ íŠ¸ë Œë“œ)
   - 61-80: ì§ì ‘ ê´€ë ¨ (íŠ¹ì • ê¸°ì—…/ì„¹í„° ë‰´ìŠ¤)
   - 81-100: ë§¤ìš° ì¤‘ìš” (ì‹¤ì , M&A, ê·œì œ ë³€í™”, ì¤‘ëŒ€ ì‚¬ê±´)

2. affected_symbols: ì˜í–¥ì„ ë°›ëŠ” ì£¼ì‹ ì‹¬ë³¼ ë¦¬ìŠ¤íŠ¸ (ìµœëŒ€ 5ê°œ)
   - ê¸°ì¡´ ì‹¬ë³¼ ê²€ì¦ ë° ì¶”ê°€ ì‹¬ë³¼ ë°œê²¬
   - ì§ì ‘ ì–¸ê¸‰ëœ ê¸°ì—…ë§Œ í¬í•¨

3. price_impact: ì£¼ê°€ ì˜í–¥ ì˜ˆì¸¡
   - "up": ê¸ì •ì  ì˜í–¥ (ë§¤ì¶œ ì¦ê°€, ì‹ ì œí’ˆ, í˜¸ì‹¤ì )
   - "down": ë¶€ì •ì  ì˜í–¥ (ì†ì‹¤, ì†Œì†¡, ê·œì œ)
   - "neutral": ì¤‘ë¦½ ë˜ëŠ” í˜¼ì¬

4. importance: ì¤‘ìš”ë„
   - "high": ì¦‰ê°ì  ì£¼ê°€ ì˜í–¥ ì˜ˆìƒ
   - "medium": ì¤‘ê¸°ì  ì˜í–¥
   - "low": ì¥ê¸°ì /ê°„ì ‘ì  ì˜í–¥

5. reasoning: ë¶„ì„ ê·¼ê±° (2-3ë¬¸ì¥)
   - ì™œ ì´ ì ìˆ˜ì¸ì§€
   - ì£¼ê°€ì— ì–´ë–¤ ì˜í–¥ì„ ì¤„ì§€
   - í•µì‹¬ íŒ©íŠ¸

6. key_points: í•µì‹¬ í¬ì¸íŠ¸ (3-5ê°œ bullet points)
   - íˆ¬ììê°€ ì•Œì•„ì•¼ í•  í•µì‹¬ ì •ë³´

ì‘ë‹µ í˜•ì‹ (JSONë§Œ ë°˜í™˜):
{{
  "relevance_score": 85,
  "affected_symbols": ["AAPL", "MSFT"],
  "price_impact": "up",
  "importance": "high",
  "reasoning": "...",
  "key_points": ["...", "...", "..."]
}}"""

    def _parse_response(self, response_text: str) -> Dict:
        """Claude Code ì‘ë‹µ íŒŒì‹±"""
        try:
            # JSON ì¶”ì¶œ ì‹œë„
            json_start = response_text.find('{')
            json_end = response_text.rfind('}') + 1

            if json_start != -1 and json_end > json_start:
                json_str = response_text[json_start:json_end]
                data = json.loads(json_str)

                # ìœ íš¨ì„± ê²€ì¦
                required_fields = ['relevance_score', 'affected_symbols', 'price_impact', 'importance']
                if not all(field in data for field in required_fields):
                    logger.error("Missing required fields in response")
                    return None

                # ê´€ë ¨ì„± ì ìˆ˜ê°€ ì„ê³„ê°’ ì´í•˜ë©´ í•„í„°ë§
                if int(data['relevance_score']) < MIN_RELEVANCE_SCORE:
                    logger.info(f"Filtered out (score: {data['relevance_score']})")
                    return None

                # íƒ€ì… ë³€í™˜
                result = {
                    'relevance_score': int(data['relevance_score']),
                    'affected_symbols': data['affected_symbols'],
                    'price_impact': PriceImpact(data['price_impact']),
                    'importance': Importance(data['importance']),
                    'reasoning': data.get('reasoning', ''),
                    'key_points': data.get('key_points', [])
                }

                logger.info(f"âœ… Analysis loaded: score {result['relevance_score']}")
                return result

        except json.JSONDecodeError as e:
            logger.error(f"JSON parsing error: {e}")
        except Exception as e:
            logger.error(f"Response parsing error: {e}")

        return None

    def batch_analyze(self, news_list: List[Dict], batch_size: int = 5) -> List[Dict]:
        """ğŸ“ ë‰´ìŠ¤ ë¶„ì„ í”„ë¡¬í”„íŠ¸ ì¼ê´„ ìƒì„± (Claude Codeê°€ ë¶„ì„)"""
        logger.info(f"ğŸ“ Generating analysis prompts for {len(news_list)} news items...")

        prompt_files = []
        for i, news in enumerate(news_list, 1):
            try:
                prompt_file = self.analyze_news(news)
                if prompt_file:
                    prompt_files.append(prompt_file)
                logger.info(f"   [{i}/{len(news_list)}] {news.get('title', 'Unknown')[:50]}")
            except Exception as e:
                logger.error(f"Error generating prompt: {e}")

        logger.info(f"âœ… Generated {len(prompt_files)} analysis prompts")
        logger.info(f"ğŸ“‚ Location: {self.prompts_dir}/")
        logger.info(f"\nğŸ’¡ Next step: ê° í”„ë¡¬í”„íŠ¸ë¥¼ Claude Codeì— ì…ë ¥í•˜ì„¸ìš”")
        logger.info(f"   ëª…ë ¹ì–´: cat prompts/analysis/*.md | wc -l")

        return []  # í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ì´ë¯€ë¡œ ì¦‰ì‹œ ê²°ê³¼ ì—†ìŒ
