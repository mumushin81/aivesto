from typing import List, Dict, Optional
from datetime import datetime
from loguru import logger
import sys
from pathlib import Path

sys.path.append('..')
from database.supabase_client import SupabaseClient
from database.models import PublishedArticle
from writers.article_formatter import ArticleFormatter

class ArticleGenerator:
    """Claude Codeë¥¼ ì‚¬ìš©í•œ ë¸”ë¡œê·¸ ê¸€ ìƒì„± (í”„ë¡¬í”„íŠ¸ ë°©ì‹)"""

    def __init__(self, db_client: SupabaseClient):
        self.db = db_client
        self.prompts_dir = Path("prompts")
        self.prompts_dir.mkdir(exist_ok=True)
        self.formatter = ArticleFormatter()
        logger.info("Article generator initialized with Claude Code mode")
        logger.info("âœ… Article quality validation enabled")

    def generate_article(self, symbol: str, max_news: int = 5) -> Optional[str]:
        """íŠ¹ì • ì¢…ëª©ì— ëŒ€í•œ ë¸”ë¡œê·¸ ê¸€ ìž‘ì„± í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        try:
            # í•´ë‹¹ ì¢…ëª© ê´€ë ¨ ë¯¸ë°œí–‰ ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
            news_items = self.db.get_unpublished_news_by_symbol(symbol, limit=max_news)

            if not news_items:
                logger.info(f"No unpublished news found for {symbol}")
                return None

            logger.info(f"ðŸ“ Generating article prompt for {symbol} with {len(news_items)} news items")

            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self._build_article_prompt(symbol, news_items)

            # í”„ë¡¬í”„íŠ¸ íŒŒì¼ ì €ìž¥
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            prompt_file = f"{self.prompts_dir}/article_{symbol}_{timestamp}.md"

            with open(prompt_file, 'w', encoding='utf-8') as f:
                f.write(prompt)

            logger.info(f"âœ… Article prompt saved: {prompt_file}")
            logger.info(f"   â†’ Claude Codeì—ì„œ í”„ë¡¬í”„íŠ¸ë¥¼ ë³µì‚¬í•˜ì—¬ ê¸€ì„ ìž‘ì„±í•˜ê³ ")
            logger.info(f"   â†’ ì™„ì„±ëœ ê¸€ì„ articles/ í´ë”ì— ì €ìž¥í•˜ì„¸ìš”")

            return None  # ìˆ˜ë™ ìž‘ì„±ì´ë¯€ë¡œ None ë°˜í™˜

        except Exception as e:
            logger.error(f"Error generating article prompt for {symbol}: {e}")

        return None

    def load_article_from_file(self, article_file: str, news_items: List[Dict]) -> Optional[str]:
        """Claude Codeì—ì„œ ìž‘ì„±í•œ ê¸€ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ìž¥ (í’ˆì§ˆ ê²€ì¦ í¬í•¨)"""
        try:
            with open(article_file, 'r', encoding='utf-8') as f:
                content = f.read()

            # ì¢…ëª© ì½”ë“œ ì¶”ì¶œ (íŒŒì¼ëª…ì—ì„œ)
            symbol = self._extract_symbol_from_filename(article_file)

            # ðŸ“Š í’ˆì§ˆ ê²€ì¦ ë° ìžë™ ìˆ˜ì •
            validation_result = self.formatter.validate_and_fix(content, symbol)

            logger.info(f"ðŸ“‹ Quality validation for {article_file}:")
            logger.info(f"   Original score: {validation_result['original_score']}/100")
            logger.info(f"   Fixed score: {validation_result['fixed_score']}/100")

            if validation_result['issues']:
                logger.warning(f"   Issues found: {len(validation_result['issues'])}")
                for issue in validation_result['issues']:
                    logger.warning(f"   - {issue}")

            if validation_result['fixes_applied']:
                logger.info(f"   Fixes applied: {len(validation_result['fixes_applied'])}")
                for fix in validation_result['fixes_applied']:
                    logger.info(f"   - {fix}")

            # ìˆ˜ì •ëœ ì½˜í…ì¸  ì‚¬ìš©
            fixed_content = validation_result['fixed_content']

            # ì œëª©ê³¼ ë³¸ë¬¸ ë¶„ë¦¬
            article_data = self._parse_article_response(fixed_content)

            if not article_data:
                return None

            # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ìž¥
            analyzed_news_ids = [news['id'] for news in news_items]
            published_article = PublishedArticle(
                title=article_data['title'],
                content=article_data['content'],
                analyzed_news_ids=analyzed_news_ids,
                published_at=datetime.now()
            )

            article_id = self.db.insert_published_article(published_article)

            if article_id:
                logger.info(f"âœ… Article saved: {article_data['title']} (Quality: {validation_result['fixed_score']}/100)")
                return article_id

        except Exception as e:
            logger.error(f"Error loading article: {e}")

        return None

    def _build_article_prompt(self, symbol: str, news_items: List[Dict]) -> str:
        """SEO ìµœì í™” ê¸€ ìž‘ì„± í”„ë¡¬í”„íŠ¸ (êµ¬ê¸€ & AI ê²€ìƒ‰ ë…¸ì¶œ ìµœìš°ì„ )"""
        # ë‰´ìŠ¤ ìš”ì•½ êµ¬ì„± (ìƒì„¸ ì •ë³´ í¬í•¨)
        news_summaries = []
        for i, news in enumerate(news_items, 1):
            raw_news = news['news_raw']
            analysis = news['analysis']
            published_date = raw_news['published_at'].split('T')[0] if 'T' in raw_news['published_at'] else raw_news['published_at']

            summary = f"""
[ë‰´ìŠ¤ {i}]
ì œëª©: {raw_news['title']}
ì¶œì²˜: {raw_news['source']}
ë°œí–‰ì¼: {published_date}
ë‚´ìš©: {raw_news['content'][:600]}

ë¶„ì„ ê²°ê³¼:
- ê´€ë ¨ì„± ì ìˆ˜: {news['relevance_score']}/100
- ì£¼ê°€ ì˜í–¥: {news['price_impact']}
- ì¤‘ìš”ë„: {analysis.get('importance', 'medium')}
- ë¶„ì„: {analysis.get('reasoning', '')}
- í•µì‹¬ í¬ì¸íŠ¸:
  {chr(10).join([f"â€¢ {point}" for point in analysis.get('key_points', [])])}
"""
            news_summaries.append(summary)

        news_context = "\n".join(news_summaries)

        return f"""ë‹¹ì‹ ì€ ë¯¸êµ­ ì£¼ì‹ ì‹œìž¥ ë¶„ì„ ì „ë¬¸ê°€ìž…ë‹ˆë‹¤.
ë‹¤ìŒ ê¸°ì¤€ìœ¼ë¡œ êµ¬ê¸€ ë° AI ê²€ìƒ‰ ì—”ì§„(Claude, ChatGPT, Gemini)ì— ë…¸ì¶œë˜ê¸° ì¢‹ì€ ê¸€ì„ í•œêµ­ì–´ë¡œ ìž‘ì„±í•´ì£¼ì„¸ìš”.

ðŸ“Š ìž‘ì„± ëŒ€ìƒ: {symbol}

ë¶„ì„ ëŒ€ìƒ ë‰´ìŠ¤:
{news_context}

================================================================================
ðŸŽ¯ ê¸€ ìž‘ì„± ê°€ì´ë“œ (SEO ìµœì í™”)
================================================================================

## âœ… í•„ìˆ˜ êµ¬ì„± (ì´ ìˆœì„œëŒ€ë¡œ)

### 1ï¸âƒ£ ì œëª© (60ìž ì´ë‚´, ê²€ìƒ‰ í´ë¦­ë¥  ê·¹ëŒ€í™”)
- ê·œì¹™: ì¢…ëª©ëª… + í•µì‹¬ ì´ìŠˆ + ìˆ˜ì¹˜ ë˜ëŠ” ì§ˆë¬¸
- ì•½í•¨: "{symbol} ìµœì‹  ë‰´ìŠ¤"
- ê°•í•¨: "{symbol} ë¹„ì¦ˆë‹ˆìŠ¤ ì „í™˜ì  + êµ¬ì²´ì  ìˆ˜ì¹˜ (ì‹œê°„)"

### 2ï¸âƒ£ 10ì´ˆ íŒë… ìš”ì•½ (AI ê²€ìƒ‰ ìµœìš°ì„ , í•„ìˆ˜)
ë‹¤ìŒ ì •í™•í•œ í˜•ì‹ìœ¼ë¡œ ìž‘ì„±:

## ðŸ“Œ í•µì‹¬ ìš”ì•½ (AI ê²€ìƒ‰ ì—”ì§„ìš©)

**ìƒí™©**: 1ì¤„ - ë°©ê¸ˆ ìžˆì€ êµ¬ì²´ì  ë‰´ìŠ¤ ì´ë²¤íŠ¸
**ì˜í–¥**: 1-2ì¤„ - ì‹œìž¥ì´ë‚˜ ì‹¤ì ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ (ìˆ˜ì¹˜ í¬í•¨)
**íˆ¬ìžìž ê´€ì **:
- ê¸ì •: [êµ¬ì²´ì  ì´ìœ  1-2ê°œ]
- ìœ„í—˜: [êµ¬ì²´ì  ì´ìœ  1-2ê°œ]
- ì‹œì‚¬ì : [êµ¬ì²´ì  ì•¡ì…˜]

### 3ï¸âƒ£ ðŸ“Š ë¬´ì—‡ì´ ì¼ì–´ë‚¬ëŠ”ê°€ (ë‰´ìŠ¤)
- ëª…í™•í•œ í—¤ë“œë¼ì¸ (í•œ ë¬¸ìž¥)
- ì–¸ì œ: ì •í™•í•œ ë‚ ì§œ ëª…ì‹œ
- ëˆ„ê°€: íšŒì‚¬ëª…, ê²½ì˜ì§„
- ë­: êµ¬ì²´ì  ì•¡ì…˜ê³¼ ìˆ˜ì¹˜
- ì¶œì²˜: ê³µì‹ ë°œí‘œ, ë§í¬ ëª…ì‹œ

### 4ï¸âƒ£ ðŸ”§ ì–´ë–»ê²Œ ìž‘ë™í•˜ëŠ”ê°€ (ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§)
- ì´ ë‰´ìŠ¤ê°€ ë¹„ì¦ˆë‹ˆìŠ¤ì— ë¯¸ì¹˜ëŠ” ë©”ì»¤ë‹ˆì¦˜ ì„¤ëª…
- ì—…ê³„ ë°°ê²½ì§€ì‹ (ì‹ ê·œ ë…ìž ê³ ë ¤)
- ê²½ìŸ êµ¬ë„ ë³€í™” (ë¹„êµ í¬í•¨)
- ì‹œìž¥ íŠ¸ë Œë“œì™€ì˜ ì—°ê²°

### 5ï¸âƒ£ ðŸ’° ì™œ ì£¼ê°€ì— ì˜í–¥ì„ ì£¼ëŠ”ê°€ (íˆ¬ìž ë¡œì§)
1. ìž¬ë¬´ ìž„íŒ©íŠ¸
   - ìˆ˜ìµì„± ê°œì„ : [êµ¬ì²´ì  ë©”ì»¤ë‹ˆì¦˜]
   - ì„±ìž¥ì„±: [êµ¬ì²´ì  ë°ì´í„°]
   - ì‹¤ì œ ìˆ˜ì¹˜: [ì •í™•í•œ ìˆ«ìž]

2. íˆ¬ìžìž ì‹¬ë¦¬
   - ì‹œìž¥ ì„ í˜¸ë„: [ê¸°ê´€íˆ¬ìžìž ì›€ì§ìž„]
   - ë¶„ì„ê°€ í‰ê°€: [ì „ë¬¸ê°€ ì˜ê²¬]
   - ë°¸ë¥˜ì—ì´ì…˜: [P/E, PEG ë“±]

3. ë‹¨ê¸° vs ìž¥ê¸° ì „ë§
   - 3-6ê°œì›”: [ì‹ í˜¸]
   - 6-12ê°œì›”: [ê¸°ëŒ€]
   - 1-3ë…„: [ìž¥ê¸° ì¶”ì„¸]

### 6ï¸âƒ£ ðŸ“ˆ ìˆ˜ì¹˜ë¡œ ë³´ëŠ” ë¶„ì„ (í‘œ í˜•ì‹)
ë§ˆí¬ë‹¤ìš´ í‘œë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹„êµ ì •ë³´ ì œì‹œ:
- {symbol} vs ê²½ìŸì‚¬ ë¹„êµ
- ì‹¤ì  ì¶”ì´ (3ë…„)
- ìœ„í—˜ ìš”ì†Œ í‰ê°€

### 7ï¸âƒ£ ðŸ¢ ê²½ìŸì‚¬ ë¹„êµ (ì°¨ë³„ì„±)
- vs ì£¼ìš” ê²½ìŸì‚¬: [ê°•ì  ë° ì•½ì ]
- ì‹œìž¥ ìœ„ì¹˜: [{symbol}ì˜ ì°¨ë³„ì„±]
- ê²°ë¡ : [ê°ê´€ì  í‰ê°€]

### 8ï¸âƒ£ â“ ìžì£¼ ë¬»ëŠ” ì§ˆë¬¸ (FAQ - ë°˜ë“œì‹œ í¬í•¨)
Q&A í˜•ì‹ìœ¼ë¡œ 5-7ê°œ ì§ˆë¬¸ì— ë‹µë³€:
- Q: "{symbol}ì„ ì§€ê¸ˆ ì‚¬ì•¼ í•˜ë‚˜?"
- Q: "{symbol} vs ê²½ìŸì‚¬ ë¹„êµ"
- Q: "ì´ ì‚°ì—…ì€ ì •ë§ ì„±ìž¥í• ê¹Œ?"
- Q: "{symbol}ì˜ ìœ„í—˜ì€?"
- Q: "ì£¼ê°€ ì „ë§ì€?"

ê° ë‹µë³€ì€ 150-300ìž, ëª…í™•í•˜ê³  ê·¼ê±° ìžˆê²Œ.

### 9ï¸âƒ£ ðŸ“° ì „ë¬¸ê°€ ì˜ê²¬ ë° ì¶œì²˜ (ì‹ ë¢°ë„)
- ì£¼ìš” ë¶„ì„ê°€ ë“±ê¸‰ (Goldman Sachs, Morgan Stanley ë“±)
- ëª©í‘œê°€ ë° ê·¼ê±°
- ê³µì‹ ê³µì‹œ ë° íˆ¬ìžìž ë¬¸ì„œ ë§í¬
- ì‹ ë¢°í•  ìˆ˜ ìžˆëŠ” ì •ë³´ì›

### ðŸ”Ÿ âš¡ ë‹¨ê³„ë³„ ì „ë§ ë¶„ì„
ë‹¨ê¸°(3-6ê°œì›”), ì¤‘ê¸°(6-12ê°œì›”), ìž¥ê¸°(1-3ë…„)ë³„ë¡œ:
- ê°•ì„¸/ì¤‘ë¦½/ì•½ì„¸ ì‹œë‚˜ë¦¬ì˜¤
- ê° ì‹œë‚˜ë¦¬ì˜¤ì˜ í™•ë¥ 
- íŠ¸ë¦¬ê±°ì™€ ëª©í‘œê°€
- ìµœì•…ì˜ ê²½ìš°ê¹Œì§€ ê³ ë ¤

### 1ï¸âƒ£1ï¸âƒ£ ðŸ” ê²°ë¡  ë° íˆ¬ìž ê³ ë ¤ì‚¬í•­
- âœ… ì¢‹ì€ ì´ìœ  (ì²´í¬ë¦¬ìŠ¤íŠ¸)
- âš ï¸ ìœ„í—˜ ìš”ì†Œ (ì²´í¬ë¦¬ìŠ¤íŠ¸)
- ðŸ“‹ íˆ¬ìž ê²°ì • ê°€ì´ë“œ (íˆ¬ìžìžë³„)
- âš–ï¸ ë²•ì  ê³ ì§€ (íˆ¬ìž ì¡°ì–¸ ì•„ë‹˜ ëª…ì‹œ)

================================================================================
ðŸ”‘ SEO í‚¤ì›Œë“œ ë°°ì¹˜ ê·œì¹™
================================================================================

1ì°¨ í‚¤ì›Œë“œ (ì¢…ëª©ëª…): ì œëª© 1íšŒ, ì²« 100ìž 1íšŒ, ë³¸ë¬¸ 1íšŒ ì´ìƒ
2ì°¨ í‚¤ì›Œë“œ (ì£¼ì œ): ìžì—°ìŠ¤ëŸ½ê²Œ 3-5íšŒ ë¶„ì‚° ë°°ì¹˜
3ì°¨ í‚¤ì›Œë“œ (Long-tail): "~í•˜ëŠ” ì´ìœ ", "~ì „ë§", "vs ë¹„êµ" í¬í•¨
4ì°¨ í‚¤ì›Œë“œ (ì˜ë„): "ë§¤ìˆ˜ ê¸°íšŒ", "íˆ¬ìž ì‹œì ", "ìœ„í—˜ ìš”ì†Œ" ìžì—°ìŠ¤ëŸ½ê²Œ í¬í•¨

ê·œì¹™: í‚¤ì›Œë“œë¥¼ ê°•ì œë¡œ ë°˜ë³µí•˜ì§€ ë§ê³ , ë¬¸ë§¥ì— ìžì—°ìŠ¤ëŸ½ê²Œ ë…¹ì´ê¸°

================================================================================
âœï¸ ìž‘ì„± ìŠ¤íƒ€ì¼
================================================================================

- ê¸€ìž ìˆ˜: 2,500-3,500ìž (ê¸°ì¡´ 1,500-2,000ì—ì„œ ì¦ê°€ - ê¹Šì´ ì¶”ê°€)
- í†¤: ì „ë¬¸ì ì´ì§€ë§Œ ì´í•´í•˜ê¸° ì‰½ê²Œ (í•™ìˆ ì  ì–¸ì–´ ì œê±°)
- ë‹¨ë½: 200ìž ì´ë‚´ (AIê°€ íŒŒì‹±í•˜ê¸° ì‰½ê²Œ)
- êµ¬ì¡°: H2(##), H3(###)ë¡œ ê³„ì¸µí™”
- ë¦¬ìŠ¤íŠ¸: ë¶ˆë¦¿(â€¢) ë˜ëŠ” ìˆ«ìžë¡œ ëª…í™•í™”
- í‘œ: ë°ì´í„° ë¹„êµëŠ” ë§ˆí¬ë‹¤ìš´ í‘œ ì‚¬ìš©
- ë§í¬: ëª¨ë“  ì¶œì²˜ì— ëª…í™•í•œ ë§í¬ í¬í•¨
- ìˆ˜ì¹˜: ì¶”ì •ì¹˜(~)ê°€ ì•„ë‹Œ ì •í™•í•œ ìˆ«ìž ì‚¬ìš©
- ë©´ì±…: "íˆ¬ìž ì¡°ì–¸ì´ ì•„ë‹™ë‹ˆë‹¤" ë°˜ë“œì‹œ í¬í•¨

================================================================================
ðŸ“‹ ìµœì¢… í˜•ì‹ (âš ï¸ í•„ìˆ˜)
================================================================================

ë°˜ë“œì‹œ ì•„ëž˜ í˜•ì‹ì„ ì •í™•ížˆ ë”°ë¥´ì„¸ìš”. ìžë™ ê²€ì¦ ì‹œìŠ¤í…œì—ì„œ í™•ì¸í•©ë‹ˆë‹¤.

```
TITLE:
[í´ë¦­ ìœ ë„ì ì¸ ì œëª© 60ìž ì´ë‚´]

CONTENT:
[ì „ì²´ ë³¸ë¬¸ - ì•„ëž˜ ëª¨ë“  ìš”êµ¬ì‚¬í•­ ì¶©ì¡±]
```

================================================================================
âœ… í’ˆì§ˆ ìš”êµ¬ì‚¬í•­ (ìžë™ ê²€ì¦)
================================================================================

ì´ ê¸€ì€ ë‹¤ìŒ ê¸°ì¤€ìœ¼ë¡œ ìžë™ ê²€ì¦ë©ë‹ˆë‹¤. ëª¨ë‘ ì¶©ì¡±í•´ì•¼ í•©ë‹ˆë‹¤:

1ï¸âƒ£ **íŒŒì¼ í˜•ì‹** (í•„ìˆ˜)
   âœ“ TITLE: / CONTENT: êµ¬ì¡° ì‚¬ìš©
   âœ“ ì „ì²´ ë§ˆí¬ë‹¤ìš´ í˜•ì‹
   âœ“ ì œëª©ì€ TITLE: ë°”ë¡œ ë’¤ì— í•œ ì¤„

2ï¸âƒ£ **í•„ìˆ˜ ì„¹ì…˜** (ë°˜ë“œì‹œ í¬í•¨)
   âœ“ "### ë¬´ìŠ¨ ì¼ì´ ì¼ì–´ë‚¬ë‚˜" - ë‰´ìŠ¤ ì‚¬ê±´ ì„¤ëª…
   âœ“ "### ì™œ ì£¼ê°€ì— ì˜í–¥ì„ ì£¼ëŠ”ê°€" - ì‹œìž¥ ì˜í–¥ ë¶„ì„
   âœ“ ìœ„ ë‘ ì„¹ì…˜ì€ ë³¸ë¬¸ ì¤‘ê°„ì— ìœ„ì¹˜í•´ì•¼ í•¨

3ï¸âƒ£ **í•œêµ­ì–´ ë¹„ìœ¨** (ìµœì†Œ 70%)
   âœ“ ì „ì²´ ë³¸ë¬¸ì˜ 70% ì´ìƒì€ í•œêµ­ì–´ì—¬ì•¼ í•¨
   âœ“ ì˜ë¬¸ ì•½ìžëŠ” í•œêµ­ì–´ ì„¤ëª… ë³‘í–‰
   âœ“ ì˜ˆ) "AI(ì¸ê³µì§€ëŠ¥)", "P/E(ì£¼ê°€ìˆ˜ìµë¹„ìœ¨)"

4ï¸âƒ£ **ë‚´ë¶€ ë§í¬** (2-5ê°œ)
   âœ“ ë§ˆí¬ë‹¤ìš´ ë§í¬ í˜•ì‹: [í…ìŠ¤íŠ¸](./articles/íŒŒì¼ëª….md)
   âœ“ ê´€ë ¨ ê¸°ì‚¬ë¥¼ ë³¸ë¬¸ ë˜ëŠ” ë§ˆì§€ë§‰ì— ë§í¬
   âœ“ ìµœì†Œ 2ê°œ, ìµœëŒ€ 5ê°œ

5ï¸âƒ£ **ë‚´ìš© ê¸¸ì´** (ìµœì†Œ 500ìž)
   âœ“ ë³¸ë¬¸ì˜ ì‹¤ì œ í•œê¸€ ë¬¸ìžê°€ 500ìž ì´ìƒ
   âœ“ ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸ë‚˜ ë§í¬ëŠ” ì œì™¸

================================================================================
âš ï¸ ê¸ˆì§€ ì‚¬í•­
================================================================================

âŒ í•˜ì§€ ë§ ê²ƒ:
- "~ì— íˆ¬ìží•˜ì„¸ìš”", "ì§€ê¸ˆ ì‚¬ì„¸ìš”" ê°™ì€ ì§ì ‘ì  ê¶Œê³ 
- ê³¼ìž¥ëœ ìˆ˜ì¹˜ ("í™•ì‹¤ížˆ 2ë°° ì˜¬ë¼ê°ˆ", "ë¬´ì¡°ê±´ ì„±ê³µ")
- ì¶œì²˜ ì—†ëŠ” ì£¼ìž¥
- ë„ˆë¬´ ê¸´ ë‹¨ë½ (200ìž ì´ˆê³¼)
- ë‹¨ì¡°ë¡œìš´ ë¬¸ìž¥ (í‘œ, ë¦¬ìŠ¤íŠ¸, ê°•ì¡°ë¡œ ì‹œê°í™”)
- ì •ì¹˜, ì¢…êµ, ìœ¤ë¦¬ ë…¼ìŸ (íˆ¬ìž ê¸€ì—ë§Œ ì§‘ì¤‘)
- TITLE: / CONTENT: í˜•ì‹ ëˆ„ë½

================================================================================

ì§€ê¸ˆ ì‹œìž‘í•˜ì„¸ìš”. ê¸€ì„ ìž‘ì„±í•œ í›„ ìœ„ì˜ í˜•ì‹ (TITLE: / CONTENT:)ë¡œ ê²°ê³¼ë¥¼ ì œì‹œí•´ì£¼ì„¸ìš”.

ðŸ“ **ì¤‘ìš”**: ìžë™ ê²€ì¦ ì‹œìŠ¤í…œì´ ë‹¤ìŒì„ í™•ì¸í•©ë‹ˆë‹¤:
   â€¢ íŒŒì¼ í˜•ì‹ (TITLE: / CONTENT:)
   â€¢ í•„ìˆ˜ ì„¹ì…˜ í¬í•¨ (ë¬´ìŠ¨ ì¼ì´/ì™œ ì£¼ê°€ì—)
   â€¢ í•œêµ­ì–´ ë¹„ìœ¨ 70% ì´ìƒ
   â€¢ ë‚´ë¶€ ë§í¬ 2-5ê°œ
   â€¢ ë‚´ìš© ê¸¸ì´ 500ìž ì´ìƒ

ëª¨ë“  ìš”êµ¬ì‚¬í•­ì„ ì¶©ì¡±í•˜ì§€ ì•Šìœ¼ë©´ ì ìˆ˜ ê°ì ê³¼ ìžë™ ìˆ˜ì •ì´ ì ìš©ë©ë‹ˆë‹¤.
"""

    def _parse_article_response(self, response_text: str) -> Optional[Dict]:
        """Claude ì‘ë‹µì—ì„œ ì œëª©ê³¼ ë³¸ë¬¸ ë¶„ë¦¬"""
        try:
            # TITLE: ê³¼ CONTENT: ë¡œ êµ¬ë¶„
            title_start = response_text.find("TITLE:")
            content_start = response_text.find("CONTENT:")

            if title_start == -1 or content_start == -1:
                # êµ¬ë¶„ìžê°€ ì—†ìœ¼ë©´ ì²« ì¤„ì„ ì œëª©ìœ¼ë¡œ
                lines = response_text.strip().split('\n')
                title = lines[0].strip()
                content = '\n'.join(lines[1:]).strip()
            else:
                title = response_text[title_start + 6:content_start].strip()
                content = response_text[content_start + 8:].strip()

            # ì œëª©ì—ì„œ ë§ˆí¬ë‹¤ìš´ ì œê±°
            title = title.replace('#', '').strip()

            return {
                'title': title,
                'content': content
            }

        except Exception as e:
            logger.error(f"Error parsing article response: {e}")
            return None

    def generate_daily_articles(self, tier: str = "tier_1", criteria_override: Dict = None) -> List[str]:
        """
        ë¶„ì„ ê¸°ì¤€ì ì— ë”°ë¼ ì—¬ëŸ¬ ê¸€ ìƒì„± í”„ë¡¬í”„íŠ¸

        Args:
            tier: "tier_1" (ë†’ì€ ì¤‘ìš”ë„ 3ê°œ+), "tier_2" (ë‰´ìŠ¤ 3ê°œ+ AND ì ìˆ˜ 75+), "tier_3" (ìƒìœ„ 15ê°œ)
            criteria_override: ê¸°ì¤€ì  ì‚¬ìš©ìž ì •ì˜ (ì„ íƒì‚¬í•­)
        """
        article_ids = []

        try:
            from config.settings import (
                ARTICLE_TIER_1_SYMBOLS, ARTICLE_TIER_2_SYMBOLS,
                ARTICLE_TIER_1_MIN_HIGH_IMPORTANCE,
                ARTICLE_TIER_2_MIN_NEWS, ARTICLE_TIER_2_MIN_SCORE,
                ARTICLE_TIER_3_TOP_N
            )
            from analyzers.analysis_pipeline import AnalysisPipeline

            pipeline = AnalysisPipeline(self.db)

            # ê¸°ì¤€ì ë³„ ì¢…ëª© ì„ íƒ
            if tier == "tier_1":
                logger.info(f"ðŸŽ¯ Generating articles for Tier 1 (High Importance >= {ARTICLE_TIER_1_MIN_HIGH_IMPORTANCE})")
                target_symbols = ARTICLE_TIER_1_SYMBOLS
                logger.info(f"   Target symbols ({len(target_symbols)}): {', '.join(target_symbols)}")

            elif tier == "tier_2":
                logger.info(f"ðŸŽ¯ Generating articles for Tier 2 (News >= {ARTICLE_TIER_2_MIN_NEWS} AND Score >= {ARTICLE_TIER_2_MIN_SCORE})")
                target_symbols = ARTICLE_TIER_1_SYMBOLS + ARTICLE_TIER_2_SYMBOLS
                logger.info(f"   Target symbols ({len(target_symbols)}): {', '.join(target_symbols)}")

            elif tier == "tier_3":
                logger.info(f"ðŸŽ¯ Generating articles for Tier 3 (Top {ARTICLE_TIER_3_TOP_N} symbols)")
                trending_symbols = pipeline.get_trending_symbols()
                target_symbols = list(trending_symbols.keys())[:ARTICLE_TIER_3_TOP_N]
                logger.info(f"   Target symbols ({len(target_symbols)}): {', '.join(target_symbols)}")

            else:
                raise ValueError(f"Invalid tier: {tier}")

            # ê¸€ ìƒì„±
            logger.info(f"\nðŸ“ Starting article generation for {len(target_symbols)} symbols...")
            for i, symbol in enumerate(target_symbols, 1):
                try:
                    result = self.generate_article(symbol)
                    logger.info(f"   [{i}/{len(target_symbols)}] {symbol}: {'Generated' if result else 'No data'}")
                    if result:
                        article_ids.append(result)
                except Exception as e:
                    logger.error(f"   [{i}/{len(target_symbols)}] {symbol}: Error - {str(e)[:50]}")

            logger.info(f"\nâœ… Article generation completed: {len(article_ids)} articles generated")
            logger.info(f"   Tier: {tier}")
            logger.info(f"   Target symbols: {len(target_symbols)}")
            logger.info(f"   Generated: {len(article_ids)}")

        except Exception as e:
            logger.error(f"Error in daily article generation: {e}")

        return article_ids

    def export_for_wordpress(self, article_id: str) -> Dict:
        """WordPress ë°œí–‰ìš© ë°ì´í„° í¬ë§·"""
        try:
            articles = self.db.get_recent_articles(days=1, limit=100)
            article = next((a for a in articles if a['id'] == article_id), None)

            if not article:
                return None

            # WordPress XML-RPC í¬ë§·
            wordpress_data = {
                'title': article['title'],
                'content': article['content'],
                'post_status': 'publish',
                'post_type': 'post',
                'comment_status': 'open',
                'categories': ['Stock Analysis', 'US Market'],
                'tags': self._extract_tags(article),
                'custom_fields': [
                    {'key': 'article_id', 'value': article_id},
                    {'key': 'generated_at', 'value': article['created_at']}
                ]
            }

            return wordpress_data

        except Exception as e:
            logger.error(f"Error exporting for WordPress: {e}")
            return None

    def _extract_tags(self, article: Dict) -> List[str]:
        """ê¸€ì—ì„œ íƒœê·¸ ì¶”ì¶œ"""
        # analyzed_news_idsë¥¼ í†µí•´ ê´€ë ¨ ì¢…ëª© ì¶”ì¶œ
        # ê°„ë‹¨ížˆ ì œëª©ì—ì„œ ì¶”ì¶œ
        tags = ['Stock News', 'US Market', 'Investment']
        return tags

    def _extract_symbol_from_filename(self, filename: str) -> Optional[str]:
        """íŒŒì¼ëª…ì—ì„œ ì¢…ëª© ì½”ë“œ ì¶”ì¶œ"""
        import re
        # article_AAPL_description_20251112.md -> AAPL
        match = re.search(r'article_([A-Z]+)_', filename)
        if match:
            return match.group(1)
        return None
