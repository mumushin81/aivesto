"""
ë¸”ë¡œê·¸ ê¸°ì‚¬ í’ˆì§ˆ ê²€ì‚¬ ìŠ¤í¬ë¦½íŠ¸
Article Quality Validation Script

11ë‹¨ê³„ êµ¬ì¡° ë° SEO ê·œì¹™ ê²€ì¦
"""

import re
import sys
import json
from pathlib import Path
from typing import Dict, List, Tuple
from datetime import datetime
from loguru import logger

sys.path.append('..')


class ArticleValidator:
    """ë¸”ë¡œê·¸ ê¸°ì‚¬ í’ˆì§ˆ ê²€ì‚¬ í´ë˜ìŠ¤"""

    # 11ë‹¨ê³„ í•„ìˆ˜ êµ¬ì¡°
    REQUIRED_SECTIONS = [
        ("ì œëª©", "title"),  # 1. ì œëª© (60ì ì´ë‚´)
        ("í•µì‹¬ ìš”ì•½", "summary"),  # 2. 10ì´ˆ ìš”ì•½
        ("ë¬´ìŠ¨ ì¼ì´ ì¼ì–´ë‚¬ë‚˜", "what_happened"),  # 3. What happened
        ("ì–´ë–»ê²Œ ì‘ë™í•˜ë‚˜", "how_it_works"),  # 4. How it works
        ("ì™œ ì£¼ê°€ì— ì˜í–¥ì„ ì£¼ë‚˜", "why_impact"),  # 5. Why it impacts
        ("ìˆ«ì ë¶„ì„", "numbers"),  # 6. Numbers
        ("ê²½ìŸì‚¬ ë¹„êµ", "competitor"),  # 7. Competitor comparison
        ("FAQ", "faq"),  # 8. FAQ
        ("ì „ë¬¸ê°€ ì˜ê²¬", "expert"),  # 9. Expert opinions
        ("ë‹¨ê³„ë³„ ì˜ˆì¸¡", "forecast"),  # 10. Phased forecast
        ("ê²°ë¡ ", "conclusion")  # 11. Conclusion
    ]

    # SEO ê·œì¹™
    SEO_RULES = {
        "title_length": (20, 60),  # ì œëª© ê¸¸ì´: 20-60ì
        "min_keywords": 3,  # ìµœì†Œ í‚¤ì›Œë“œ ìˆ˜
        "keyword_density": (1, 3),  # í‚¤ì›Œë“œ ë°€ë„: 1-3%
        "heading_count": (5, 20),  # í—¤ë”© ìˆ˜: 5-20ê°œ
        "paragraph_length": (50, 300),  # ë¬¸ë‹¨ ê¸¸ì´: 50-300ì
        "internal_links": (2, 10),  # ë‚´ë¶€ ë§í¬: 2-10ê°œ
        "meta_description": (120, 160),  # ë©”íƒ€ ì„¤ëª…: 120-160ì
        "readability_score": 60,  # ê°€ë…ì„± ì ìˆ˜: 60 ì´ìƒ
    }

    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.validation_results = {}
        self.errors = []
        self.warnings = []
        self.suggestions = []

    def validate_article(self, file_path: str) -> Dict:
        """
        ê¸°ì‚¬ íŒŒì¼ ê²€ì¦

        Args:
            file_path: ê¸°ì‚¬ íŒŒì¼ ê²½ë¡œ

        Returns:
            ê²€ì¦ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        self.errors = []
        self.warnings = []
        self.suggestions = []

        if not Path(file_path).exists():
            logger.error(f"File not found: {file_path}")
            return {"status": "error", "message": f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {file_path}"}

        # íŒŒì¼ ì½ê¸°
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
        except Exception as e:
            logger.error(f"Failed to read file: {e}")
            return {"status": "error", "message": f"íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}"}

        # ê¸°ë³¸ ê²€ì¦
        self._validate_file_format(content)
        self._validate_structure(content)
        self._validate_seo(content)
        self._validate_writing_rules(content)

        # ê²°ê³¼ ì¢…í•©
        total_checks = 11  # 11ë‹¨ê³„
        passed_sections = self._count_sections(content)

        result = {
            "status": "success" if not self.errors else "warning",
            "file": Path(file_path).name,
            "timestamp": datetime.now().isoformat(),
            "sections_passed": passed_sections,
            "total_sections": total_checks,
            "completion_rate": f"{int((passed_sections / total_checks) * 100)}%",
            "errors": self.errors,
            "warnings": self.warnings,
            "suggestions": self.suggestions,
            "score": self._calculate_score()
        }

        return result

    def _validate_file_format(self, content: str):
        """íŒŒì¼ í˜•ì‹ ê²€ì¦"""
        # TITLEê³¼ CONTENT êµ¬ë¶„ í™•ì¸
        if "TITLE:" not in content or "CONTENT:" not in content:
            self.errors.append("âŒ íŒŒì¼ í˜•ì‹: TITLE: / CONTENT: êµ¬ì¡° ì—†ìŒ")
        else:
            self.suggestions.append("âœ… ê¸°ë³¸ íŒŒì¼ í˜•ì‹ ì¤€ìˆ˜")

        # ê¸°ë³¸ ë‚´ìš© ê¸¸ì´
        content_section = content.split("CONTENT:")[-1].strip() if "CONTENT:" in content else ""
        if len(content_section) < 500:
            self.errors.append(f"âŒ ë‚´ìš© ê¸¸ì´ ë¶€ì¡±: {len(content_section)}ì (ìµœì†Œ 500ì ê¶Œì¥)")
        elif len(content_section) < 1000:
            self.warnings.append(f"âš ï¸ ë‚´ìš© ê¸¸ì´ ë¶€ì¡±: {len(content_section)}ì (ê¶Œì¥: 1000-3000ì)")

    def _validate_structure(self, content: str):
        """11ë‹¨ê³„ êµ¬ì¡° ê²€ì¦"""
        content_lower = content.lower()
        section_mapping = {
            "ë¬´ìŠ¨ ì¼ì´ ì¼ì–´ë‚¬ë‚˜": ["ë¬´ìŠ¨ ì¼ì´ ì¼ì–´ë‚¬ë‚˜", "what happened", "ë‰´ìŠ¤ ë‚´ìš©", "ì‚¬ê±´"],
            "ì–´ë–»ê²Œ ì‘ë™í•˜ë‚˜": ["ì–´ë–»ê²Œ ì‘ë™í•˜ë‚˜", "how it works", "ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§", "ì‘ë™ ë°©ì‹"],
            "ì™œ ì£¼ê°€ì— ì˜í–¥ì„ ì£¼ë‚˜": ["ì™œ ì£¼ê°€ì— ì˜í–¥", "why it impacts", "ì£¼ê°€ ì˜í–¥", "íˆ¬ì ê´€ì "],
            "ìˆ«ì ë¶„ì„": ["ìˆ«ì", "ìˆ˜ì¹˜", "í†µê³„", "ë°ì´í„°", "numbers", "figure"],
            "ê²½ìŸì‚¬ ë¹„êµ": ["ê²½ìŸì‚¬", "ê²½ìŸ", "ë¹„êµ", "competitor", "comparison"],
            "FAQ": ["faq", "ìì£¼ ë¬»ëŠ” ì§ˆë¬¸", "ì§ˆë¬¸ê³¼ ë‹µë³€", "q&a"],
            "ì „ë¬¸ê°€ ì˜ê²¬": ["ì „ë¬¸ê°€", "ì• ë„ë¦¬ìŠ¤íŠ¸", "ì˜ê²¬", "í‰ê°€", "expert", "analyst"],
            "ë‹¨ê³„ë³„ ì˜ˆì¸¡": ["ì˜ˆì¸¡", "ì „ë§", "ì‹œë‚˜ë¦¬ì˜¤", "ë‹¨ê¸°", "ì¤‘ê¸°", "ì¥ê¸°", "forecast"],
            "ê²°ë¡ ": ["ê²°ë¡ ", "ì¢…í•©", "ì •ë¦¬", "ìš”ì•½", "conclusion", "summary"]
        }

        found_sections = {}
        for section_name, keywords in section_mapping.items():
            for keyword in keywords:
                if keyword in content_lower:
                    found_sections[section_name] = True
                    break

        # í•„ìˆ˜ ì„¹ì…˜ í™•ì¸
        essential_sections = ["ë¬´ìŠ¨ ì¼ì´ ì¼ì–´ë‚¬ë‚˜", "ì™œ ì£¼ê°€ì— ì˜í–¥ì„ ì£¼ë‚˜", "ê²°ë¡ "]
        missing_sections = [s for s in essential_sections if s not in found_sections]

        if missing_sections:
            for section in missing_sections:
                self.errors.append(f"âŒ í•„ìˆ˜ ì„¹ì…˜ ëˆ„ë½: {section}")

        for section_name in found_sections:
            self.suggestions.append(f"âœ… êµ¬ì¡° í™•ì¸: {section_name} í¬í•¨")

        # í—¤ë”© ê°œìˆ˜ í™•ì¸
        headings = re.findall(r'^#{1,3}\s+.+$', content, re.MULTILINE)
        if len(headings) < 3:
            self.warnings.append(f"âš ï¸ í—¤ë”© ë¶€ì¡±: {len(headings)}ê°œ (ê¶Œì¥: 5ê°œ ì´ìƒ)")
        else:
            self.suggestions.append(f"âœ… êµ¬ì¡° í—¤ë”©: {len(headings)}ê°œ ì‚¬ìš©")

    def _validate_seo(self, content: str):
        """SEO ê·œì¹™ ê²€ì¦"""
        # ì œëª© ê¸¸ì´ í™•ì¸
        title_match = re.search(r'TITLE:\s*\n?(.+?)(?:\n|$)', content)
        if title_match:
            title = title_match.group(1).strip()
            title_length = len(title)
            if title_length < 20:
                self.errors.append(f"âŒ SEO ì œëª© ê¸¸ì´ ì§§ìŒ: {title_length}ì (ê¶Œì¥: 20-60ì)")
            elif title_length > 60:
                self.errors.append(f"âŒ SEO ì œëª© ê¸¸ì´ ê¹€: {title_length}ì (ê¶Œì¥: 20-60ì)")
            else:
                self.suggestions.append(f"âœ… SEO ì œëª©: {title_length}ì (ìµœì )")

            # í‚¤ì›Œë“œ í™•ì¸ (ì¢…ëª©ëª…, í•µì‹¬ ìš©ì–´)
            keywords = self._extract_keywords(title)
            if len(keywords) >= 2:
                self.suggestions.append(f"âœ… ì œëª© í‚¤ì›Œë“œ: {len(keywords)}ê°œ í¬í•¨")
            else:
                self.warnings.append(f"âš ï¸ ì œëª© í‚¤ì›Œë“œ ë¶€ì¡±: {len(keywords)}ê°œ (ê¶Œì¥: 2ê°œ ì´ìƒ)")

        # ë¬¸ë‹¨ ê¸¸ì´ í™•ì¸
        paragraphs = re.split(r'\n\n+', content)
        short_paragraphs = [p for p in paragraphs if len(p) < 50 and len(p) > 5]
        if short_paragraphs:
            self.warnings.append(f"âš ï¸ ì§§ì€ ë¬¸ë‹¨: {len(short_paragraphs)}ê°œ (ê¶Œì¥: 50ì ì´ìƒ)")

        # ìˆ«ì ì‚¬ìš© í™•ì¸
        numbers = re.findall(r'\d+(?:%|ë…„|ì›”|ì¼|B|M|K|$)?', content)
        if len(numbers) >= 5:
            self.suggestions.append(f"âœ… ìˆ«ì í™œìš©: {len(numbers)}ê°œ í†µê³„/ìˆ˜ì¹˜ í¬í•¨")
        else:
            self.warnings.append(f"âš ï¸ ìˆ«ì ë¶€ì¡±: {len(numbers)}ê°œ (ê¶Œì¥: 5ê°œ ì´ìƒ)")

        # ë‚´ë¶€ ë§í¬ í™•ì¸
        links = re.findall(r'\[.+?\]\(.+?\)', content)
        if len(links) >= 2:
            self.suggestions.append(f"âœ… ë‚´ë¶€ ë§í¬: {len(links)}ê°œ í¬í•¨")
        elif len(links) == 0:
            self.warnings.append(f"âš ï¸ ë§í¬ ì—†ìŒ (ê¶Œì¥: 2-5ê°œ ë‚´ë¶€ ë§í¬)")

    def _validate_writing_rules(self, content: str):
        """ê¸€ì“°ê¸° ë¬¸ì„œí™” ê·œì¹™ ê²€ì¦"""
        issues = []

        # 1. í•œêµ­ì–´/ì˜ì–´ í˜¼ìš© ê²€ì¦
        korean_ratio = self._calculate_korean_ratio(content)
        if korean_ratio < 70:
            self.warnings.append(f"âš ï¸ í•œêµ­ì–´ ë¹„ìœ¨ ë‚®ìŒ: {korean_ratio:.1f}% (ê¶Œì¥: 70% ì´ìƒ)")
        else:
            self.suggestions.append(f"âœ… í•œêµ­ì–´ ë¹„ìœ¨: {korean_ratio:.1f}%")

        # 2. ë¬¸ì¥ ê¸¸ì´ ê²€ì¦
        sentences = re.split(r'[.!?]\s+', content)
        long_sentences = [s for s in sentences if len(s) > 100]
        if len(long_sentences) > len(sentences) * 0.3:  # 30% ì´ìƒ ê¸¸ë©´ ê²½ê³ 
            self.warnings.append(f"âš ï¸ ê¸´ ë¬¸ì¥ ë§ìŒ: {len(long_sentences)}ê°œ (ê¶Œì¥: í‰ê·  40-80ì)")

        # 3. ë¶ˆë¦¿ í¬ì¸íŠ¸ ì‚¬ìš©
        bullets = re.findall(r'^[\s]*[-â€¢*]\s+.+$', content, re.MULTILINE)
        if len(bullets) >= 3:
            self.suggestions.append(f"âœ… ë¶ˆë¦¿ í¬ì¸íŠ¸: {len(bullets)}ê°œ ì‚¬ìš©")
        else:
            self.warnings.append(f"âš ï¸ ë¶ˆë¦¿ í¬ì¸íŠ¸ ë¶€ì¡±: {len(bullets)}ê°œ (ê¶Œì¥: 3ê°œ ì´ìƒ)")

        # 4. ì´ëª¨ì§€ ì‚¬ìš© ì ì ˆì„± (ì´ëª¨ì§€ ê°œìˆ˜ë§Œ ê°„ë‹¨íˆ ê³„ì‚°)
        emojis = [c for c in content if ord(c) > 0x1F000]  # ì´ëª¨ì§€ëŠ” ë†’ì€ ìœ ë‹ˆì½”ë“œ ë²”ìœ„
        if 0 < len(emojis) <= 10:
            self.suggestions.append(f"âœ… ì´ëª¨ì§€ ì‚¬ìš©: {len(emojis)}ê°œ (ì ì ˆí•œ ìˆ˜ì¤€)")
        elif len(emojis) == 0:
            self.warnings.append(f"âš ï¸ ì´ëª¨ì§€ ì—†ìŒ (ê¶Œì¥: 2-5ê°œ)")
        else:
            self.warnings.append(f"âš ï¸ ì´ëª¨ì§€ ê³¼ë‹¤: {len(emojis)}ê°œ (ê¶Œì¥: 2-10ê°œ)")

        # 5. í‘œ(Table) ì‚¬ìš©
        tables = re.findall(r'\|.*\|', content)
        if len(tables) >= 1:
            self.suggestions.append(f"âœ… ë¹„êµ í‘œ: {len(tables)}ê°œ í¬í•¨")

        # 6. ì¸ìš©êµ¬ ì‚¬ìš©
        quotes = re.findall(r'> .+', content)
        if len(quotes) >= 1:
            self.suggestions.append(f"âœ… ì¸ìš©êµ¬: {len(quotes)}ê°œ í¬í•¨")

        # 7. ì½”ë“œ/ê°•ì¡° ë¸”ë¡
        code_blocks = re.findall(r'`{1,3}[\s\S]*?`{1,3}', content)
        if len(code_blocks) >= 1:
            self.suggestions.append(f"âœ… ì½”ë“œ/ê°•ì¡°: {len(code_blocks)}ê°œ í¬í•¨")

        # 8. í—¤ë”© ê³„ì¸µ êµ¬ì¡°
        h1s = len(re.findall(r'^# ', content, re.MULTILINE))
        h2s = len(re.findall(r'^## ', content, re.MULTILINE))
        if h1s > 1:
            self.warnings.append(f"âš ï¸ H1 í—¤ë”© ê³¼ë‹¤: {h1s}ê°œ (ê¶Œì¥: 1ê°œ)")
        if h2s >= 3:
            self.suggestions.append(f"âœ… H2 í—¤ë”©: {h2s}ê°œ (ì ì ˆ)")

        # 9. ë¬¸ë‹¨ ë‹¨ë½ í™•ì¸
        paragraphs = re.split(r'\n\n+', content)
        if len(paragraphs) >= 10:
            self.suggestions.append(f"âœ… ë¬¸ë‹¨ êµ¬ì¡°: {len(paragraphs)}ê°œ ë‹¨ë½ (ì ì ˆ)")
        else:
            self.warnings.append(f"âš ï¸ ë¬¸ë‹¨ ë¶€ì¡±: {len(paragraphs)}ê°œ (ê¶Œì¥: 10ê°œ ì´ìƒ)")

        # 10. ê²°ë¡ /í–‰ë™ ìœ ë„ í™•ì¸
        if any(word in content.lower() for word in ['ê²°ë¡ ', 'ì¢…í•©', 'ì•¡ì…˜', 'íˆ¬ì', 'ì²´í¬ë¦¬ìŠ¤íŠ¸', 'cta']):
            self.suggestions.append(f"âœ… ëª…í™•í•œ ê²°ë¡ /CTA í¬í•¨")
        else:
            self.warnings.append(f"âš ï¸ ëª…í™•í•œ ê²°ë¡  ë¶€ì¡±")

    def _extract_keywords(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        # ê¸°ë³¸ í‚¤ì›Œë“œ: ëŒ€ë¬¸ì, ìˆ«ì í¬í•¨ ë‹¨ì–´
        words = text.split()
        keywords = [w for w in words if (w[0].isupper() or any(c.isdigit() for c in w)) and len(w) > 2]
        return keywords[:5]  # ìƒìœ„ 5ê°œë§Œ

    def _calculate_korean_ratio(self, text: str) -> float:
        """í•œêµ­ì–´ ë¹„ìœ¨ ê³„ì‚°"""
        korean_chars = len(re.findall(r'[ê°€-í£]', text))
        total_chars = len(re.sub(r'[\s\n\t]', '', text))
        return (korean_chars / total_chars * 100) if total_chars > 0 else 0

    def _count_sections(self, content: str) -> int:
        """11ë‹¨ê³„ ì„¹ì…˜ ê°œìˆ˜ ê³„ì‚°"""
        section_keywords = [
            r'ë¬´ìŠ¨.*ì¼',
            r'ì–´ë–»ê²Œ.*ì‘ë™',
            r'ì™œ.*ì˜í–¥',
            r'ìˆ«ì|í†µê³„|ë°ì´í„°',
            r'ê²½ìŸ|ë¹„êµ',
            r'(?:faq|ìì£¼)',
            r'ì „ë¬¸ê°€|ì• ë„ë¦¬ìŠ¤íŠ¸',
            r'ì˜ˆì¸¡|ì „ë§',
            r'ê²°ë¡ |ì¢…í•©'
        ]

        found = sum(1 for keyword in section_keywords if re.search(keyword, content, re.IGNORECASE))
        return min(found + 2, 11)  # ìµœëŒ€ 11

    def _calculate_score(self) -> int:
        """ì¢…í•© ì ìˆ˜ ê³„ì‚° (0-100)"""
        base_score = 100
        base_score -= len(self.errors) * 20  # ê° ì˜¤ë¥˜ -20ì 
        base_score -= len(self.warnings) * 5  # ê° ê²½ê³  -5ì 
        base_score += len(self.suggestions) * 3  # ê° ê¸ì • +3ì 
        return max(0, min(100, base_score))

    def validate_directory(self, dir_path: str, output_file: str = None) -> Dict:
        """
        ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  ê¸°ì‚¬ ê²€ì¦

        Args:
            dir_path: ê¸°ì‚¬ ë””ë ‰í† ë¦¬ ê²½ë¡œ
            output_file: ê²°ê³¼ ì €ì¥ íŒŒì¼ (ì„ íƒì‚¬í•­)

        Returns:
            ê²€ì¦ ê²°ê³¼ ì¢…í•©
        """
        dir_path = Path(dir_path)
        if not dir_path.exists():
            logger.error(f"Directory not found: {dir_path}")
            return {"status": "error", "message": f"ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {dir_path}"}

        results = []
        md_files = list(dir_path.glob("*.md"))

        logger.info(f"Validating {len(md_files)} articles in {dir_path}")

        for file_path in md_files:
            result = self.validate_article(str(file_path))
            results.append(result)

        # ì¢…í•© í†µê³„
        summary = {
            "total_files": len(md_files),
            "validated_files": len(results),
            "average_score": sum(r.get('score', 0) for r in results) / len(results) if results else 0,
            "high_quality": sum(1 for r in results if r.get('score', 0) >= 80),
            "medium_quality": sum(1 for r in results if 60 <= r.get('score', 0) < 80),
            "low_quality": sum(1 for r in results if r.get('score', 0) < 60),
            "results": results
        }

        # ê²°ê³¼ ì €ì¥
        if output_file:
            try:
                with open(output_file, 'w', encoding='utf-8') as f:
                    json.dump(summary, f, ensure_ascii=False, indent=2)
                logger.info(f"Validation results saved to {output_file}")
            except Exception as e:
                logger.error(f"Failed to save results: {e}")

        return summary

    def print_report(self, result: Dict, verbose: bool = False):
        """ê²€ì¦ ê²°ê³¼ ë¦¬í¬íŠ¸ ì¶œë ¥"""
        print("\n" + "=" * 70)
        print(f"ğŸ“‹ ê¸°ì‚¬ í’ˆì§ˆ ê²€ì‚¬ ê²°ê³¼")
        print("=" * 70)

        print(f"\nğŸ“„ íŒŒì¼ëª…: {result.get('file', 'Unknown')}")
        print(f"â° ê²€ì‚¬ ì‹œê°„: {result.get('timestamp', 'Unknown')}")
        print(f"\nğŸ“Š ì¢…í•© ì ìˆ˜: {result.get('score', 0)}/100")
        print(f"âœ… êµ¬ì¡° ì™„ì„±ë„: {result.get('completion_rate', '0%')}")

        # ì˜¤ë¥˜ í‘œì‹œ
        if result.get('errors'):
            print(f"\nğŸ”´ ì˜¤ë¥˜ ({len(result['errors'])}ê°œ):")
            for error in result['errors']:
                print(f"  {error}")

        # ê²½ê³  í‘œì‹œ
        if result.get('warnings'):
            print(f"\nğŸŸ¡ ê²½ê³  ({len(result['warnings'])}ê°œ):")
            for warning in result['warnings']:
                print(f"  {warning}")

        # ì œì•ˆ í‘œì‹œ
        if verbose and result.get('suggestions'):
            print(f"\nâœ… ê¸ì • ({len(result['suggestions'])}ê°œ):")
            for suggestion in result['suggestions'][:5]:
                print(f"  {suggestion}")
            if len(result['suggestions']) > 5:
                print(f"  ... ì™¸ {len(result['suggestions']) - 5}ê°œ")

        print("\n" + "=" * 70)


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse

    parser = argparse.ArgumentParser(description="ë¸”ë¡œê·¸ ê¸°ì‚¬ í’ˆì§ˆ ê²€ì‚¬")
    parser.add_argument("--file", help="ê²€ì‚¬í•  ê¸°ì‚¬ íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--dir", help="ê²€ì‚¬í•  ê¸°ì‚¬ ë””ë ‰í† ë¦¬ ê²½ë¡œ")
    parser.add_argument("--output", help="ê²°ê³¼ ì €ì¥ íŒŒì¼ ê²½ë¡œ (JSON)")
    parser.add_argument("--verbose", action="store_true", help="ìƒì„¸ ì¶œë ¥")

    args = parser.parse_args()

    validator = ArticleValidator()

    if args.file:
        # ë‹¨ì¼ íŒŒì¼ ê²€ì¦
        result = validator.validate_article(args.file)
        validator.print_report(result, verbose=args.verbose)

    elif args.dir:
        # ë””ë ‰í† ë¦¬ ê²€ì¦
        summary = validator.validate_directory(args.dir, args.output)
        print("\n" + "=" * 70)
        print("ğŸ“Š ì¢…í•© ê²€ì¦ ê²°ê³¼")
        print("=" * 70)
        print(f"\nì´ íŒŒì¼ ìˆ˜: {summary['total_files']}")
        print(f"í‰ê·  ì ìˆ˜: {summary['average_score']:.1f}/100")
        print(f"ğŸŸ¢ ë†’ìŒ (80ì  ì´ìƒ): {summary['high_quality']}ê°œ")
        print(f"ğŸŸ¡ ì¤‘ê°„ (60-79ì ): {summary['medium_quality']}ê°œ")
        print(f"ğŸ”´ ë‚®ìŒ (60ì  ë¯¸ë§Œ): {summary['low_quality']}ê°œ")

        if args.verbose:
            print("\nğŸ“‹ ê°œë³„ íŒŒì¼ ê²°ê³¼:")
            for result in summary['results']:
                print(f"\n  â€¢ {result['file']}: {result['score']}/100 ({result['completion_rate']})")

    else:
        parser.print_help()


if __name__ == "__main__":
    main()
