#!/usr/bin/env python3
"""
ê±°ì‹œê²½ì œ(Macro) ë‰´ìŠ¤ ìˆ˜ì§‘ê¸°

ìˆ˜ì§‘ ëŒ€ìƒ:
- CPI, PPI (ì†Œë¹„ì/ìƒì‚°ì ë¬¼ê°€ì§€ìˆ˜)
- ê³ ìš©ì§€í‘œ: NFP, ì‹¤ì—…ë¥ 
- FOMC: ì˜ì‚¬ë¡, ê¸ˆë¦¬ ê²°ì •
- ì†Œë§¤íŒë§¤, ì œì¡°ì—… PMI
- GDP ì„±ì¥ë¥ 
- ì†Œë¹„ìì‹ ë¢°ì§€ìˆ˜
- ë¯¸ ì¬ë¬´ë¶€/ì—°ì¤€ ë°œì–¸

ë°ì´í„° ì†ŒìŠ¤:
- CNBC Economy API
- Bloomberg Markets
- Investing.com Economic Calendar
- Reuters Economics
- ë¯¸êµ­ ì •ë¶€ ê³µì‹ ë¦¬í¬íŠ¸ (BEA, BLS)
"""

import os
import requests
from datetime import datetime, timedelta
from dotenv import load_dotenv
from loguru import logger
from supabase import create_client
from typing import List, Dict, Any

load_dotenv()


class MacroNewsCollector:
    """ê±°ì‹œê²½ì œ ë‰´ìŠ¤ ìˆ˜ì§‘ê¸°"""

    def __init__(self):
        self.supabase_url = os.getenv("SUPABASE_URL")
        self.supabase_key = os.getenv("SUPABASE_KEY")
        self.supabase = create_client(self.supabase_url, self.supabase_key)

        # API Keys (í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì •)
        self.alpha_vantage_key = os.getenv("ALPHA_VANTAGE_API_KEY")
        self.fred_key = os.getenv("FRED_API_KEY")  # Federal Reserve Economic Data

    def collect_cpi_data(self) -> List[Dict[str, Any]]:
        """
        CPI (Consumer Price Index) ë°ì´í„° ìˆ˜ì§‘
        Source: FRED API
        """
        logger.info("ğŸ“Š CPI ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")

        if not self.fred_key:
            logger.warning("FRED_API_KEY not set")
            return []

        try:
            url = f"https://api.stlouisfed.org/fred/series/observations"
            params = {
                "series_id": "CPIAUCSL",  # CPI for All Urban Consumers
                "api_key": self.fred_key,
                "file_type": "json",
                "limit": 12,  # ìµœê·¼ 12ê°œì›”
                "sort_order": "desc"
            }

            response = requests.get(url, params=params)
            response.raise_for_status()

            data = response.json()
            observations = data.get("observations", [])

            cpi_data = []
            for obs in observations:
                cpi_data.append({
                    "date": obs.get("date"),
                    "value": float(obs.get("value", 0)),
                    "indicator": "CPI"
                })

            logger.success(f"  âœ… CPI ë°ì´í„° {len(cpi_data)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")
            return cpi_data

        except Exception as e:
            logger.error(f"  âŒ CPI ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return []

    def collect_unemployment_data(self) -> List[Dict[str, Any]]:
        """
        ì‹¤ì—…ë¥  ë°ì´í„° ìˆ˜ì§‘
        Source: FRED API
        """
        logger.info("ğŸ“Š ì‹¤ì—…ë¥  ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")

        if not self.fred_key:
            logger.warning("FRED_API_KEY not set")
            return []

        try:
            url = f"https://api.stlouisfed.org/fred/series/observations"
            params = {
                "series_id": "UNRATE",  # Unemployment Rate
                "api_key": self.fred_key,
                "file_type": "json",
                "limit": 12,
                "sort_order": "desc"
            }

            response = requests.get(url, params=params)
            response.raise_for_status()

            data = response.json()
            observations = data.get("observations", [])

            unemployment_data = []
            for obs in observations:
                unemployment_data.append({
                    "date": obs.get("date"),
                    "value": float(obs.get("value", 0)),
                    "indicator": "UNEMPLOYMENT_RATE"
                })

            logger.success(f"  âœ… ì‹¤ì—…ë¥  ë°ì´í„° {len(unemployment_data)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")
            return unemployment_data

        except Exception as e:
            logger.error(f"  âŒ ì‹¤ì—…ë¥  ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return []

    def collect_gdp_data(self) -> List[Dict[str, Any]]:
        """
        GDP ì„±ì¥ë¥  ë°ì´í„° ìˆ˜ì§‘
        Source: FRED API
        """
        logger.info("ğŸ“Š GDP ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")

        if not self.fred_key:
            logger.warning("FRED_API_KEY not set")
            return []

        try:
            url = f"https://api.stlouisfed.org/fred/series/observations"
            params = {
                "series_id": "GDP",  # Gross Domestic Product
                "api_key": self.fred_key,
                "file_type": "json",
                "limit": 8,  # ìµœê·¼ 8ë¶„ê¸° (2ë…„)
                "sort_order": "desc"
            }

            response = requests.get(url, params=params)
            response.raise_for_status()

            data = response.json()
            observations = data.get("observations", [])

            gdp_data = []
            for obs in observations:
                gdp_data.append({
                    "date": obs.get("date"),
                    "value": float(obs.get("value", 0)),
                    "indicator": "GDP"
                })

            logger.success(f"  âœ… GDP ë°ì´í„° {len(gdp_data)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")
            return gdp_data

        except Exception as e:
            logger.error(f"  âŒ GDP ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return []

    def collect_fomc_calendar(self) -> List[Dict[str, Any]]:
        """
        FOMC íšŒì˜ ì¼ì • ìˆ˜ì§‘
        Source: Federal Reserve ê³µì‹ ì›¹ì‚¬ì´íŠ¸ (ìŠ¤í¬ë˜í•‘)
        """
        logger.info("ğŸ“Š FOMC ì¼ì • ìˆ˜ì§‘ ì¤‘...")

        # TODO: Federal Reserve ì›¹ì‚¬ì´íŠ¸ ìŠ¤í¬ë˜í•‘
        # https://www.federalreserve.gov/monetarypolicy/fomccalendars.htm

        # ì„ì‹œ ë°ì´í„° (ì‹¤ì œ êµ¬í˜„ ì‹œ ìŠ¤í¬ë˜í•‘ í•„ìš”)
        fomc_data = [
            {
                "date": "2025-01-29",
                "event": "FOMC Meeting",
                "description": "Federal Open Market Committee Meeting"
            },
            {
                "date": "2025-03-19",
                "event": "FOMC Meeting",
                "description": "Federal Open Market Committee Meeting"
            }
        ]

        logger.success(f"  âœ… FOMC ì¼ì • {len(fomc_data)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")
        return fomc_data

    def analyze_macro_signal(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """
        ê±°ì‹œê²½ì œ ë°ì´í„°ì—ì„œ ì‹œê·¸ë„ ë¶„ì„

        ì‹œê·¸ë„ í¬ì¸íŠ¸:
        - CPI > ì˜ˆìƒ â†’ Tech/ì„±ì¥ì£¼ í•˜ë½
        - ì‹¤ì—…ë¥  < ì˜ˆìƒ â†’ ë‹¬ëŸ¬ ê°•ì„¸ â†’ ë‚˜ìŠ¤ë‹¥ í•˜ë½
        - GDP ê°•ì„¸ â†’ ê¸ˆë¦¬ ìƒìŠ¹ ê¸°ëŒ€
        """

        indicator = data.get("indicator")
        value = data.get("value", 0)

        signal = {
            "indicator": indicator,
            "value": value,
            "date": data.get("date"),
            "signal": None,
            "affected_sectors": [],
            "impact_level": "MEDIUM"
        }

        # CPI ì‹œê·¸ë„
        if indicator == "CPI":
            # ì „ì›” ëŒ€ë¹„ ì¦ê°€ìœ¨ ê³„ì‚° (ì‹¤ì œë¡œëŠ” consensusì™€ ë¹„êµ)
            if value > 3.0:  # ì„ê³„ê°’ (ì‹¤ì œë¡œëŠ” ë™ì ìœ¼ë¡œ ê³„ì‚°)
                signal["signal"] = "TECH_GROWTH_SHORT_TERM_DOWN"
                signal["affected_sectors"] = ["TECH", "GROWTH_STOCKS"]
                signal["impact_level"] = "HIGH"
            elif value < 2.0:
                signal["signal"] = "RISK_ON_RALLY"
                signal["affected_sectors"] = ["TECH", "GROWTH_STOCKS"]
                signal["impact_level"] = "HIGH"

        # ì‹¤ì—…ë¥  ì‹œê·¸ë„
        elif indicator == "UNEMPLOYMENT_RATE":
            if value < 4.0:  # ë‚®ì€ ì‹¤ì—…ë¥  â†’ ê²½ê¸° ê³¼ì—´ ìš°ë ¤
                signal["signal"] = "DOLLAR_STRONG_NASDAQ_DOWN"
                signal["affected_sectors"] = ["NASDAQ", "QQQ"]
                signal["impact_level"] = "HIGH"
            elif value > 5.0:  # ë†’ì€ ì‹¤ì—…ë¥  â†’ ê²½ê¸° ë‘”í™”
                signal["signal"] = "RECESSION_RISK"
                signal["affected_sectors"] = ["ALL"]
                signal["impact_level"] = "CRITICAL"

        # GDP ì‹œê·¸ë„
        elif indicator == "GDP":
            # ì „ë¶„ê¸° ëŒ€ë¹„ ì¦ê°€ìœ¨ (ì‹¤ì œë¡œëŠ” ê³„ì‚° í•„ìš”)
            if value > 20000:  # ì„ì‹œ ê¸°ì¤€ (ì‹¤ì œë¡œëŠ” YoY ì„±ì¥ë¥ )
                signal["signal"] = "ECONOMY_STRONG_RATE_HIKE_RISK"
                signal["affected_sectors"] = ["BONDS", "TECH"]
                signal["impact_level"] = "HIGH"

        return signal

    def save_to_database(self, data: List[Dict[str, Any]]):
        """ìˆ˜ì§‘í•œ ë°ì´í„°ë¥¼ Supabaseì— ì €ì¥"""

        logger.info("ğŸ’¾ Supabaseì— ì €ì¥ ì¤‘...")

        for item in data:
            try:
                # macro_news í…Œì´ë¸”ì— ì €ì¥
                result = self.supabase.table('macro_news').insert({
                    "event_type": item.get("indicator"),
                    "actual": item.get("value"),
                    "consensus": None,  # TODO: consensus ë°ì´í„° ì¶”ê°€
                    "previous": None,  # TODO: previous ë°ì´í„° ì¶”ê°€
                    "impact": "HIGH",
                    "affected_sectors": item.get("affected_sectors", []),
                }).execute()

                logger.success(f"  âœ… {item.get('indicator')} ì €ì¥ ì™„ë£Œ")

            except Exception as e:
                logger.error(f"  âŒ ì €ì¥ ì‹¤íŒ¨: {e}")

    def run(self):
        """ê±°ì‹œê²½ì œ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤í–‰"""

        logger.info("=" * 60)
        logger.info("ğŸš€ ê±°ì‹œê²½ì œ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘")
        logger.info("=" * 60)

        all_data = []

        # 1. CPI ë°ì´í„°
        cpi_data = self.collect_cpi_data()
        all_data.extend(cpi_data)

        # 2. ì‹¤ì—…ë¥  ë°ì´í„°
        unemployment_data = self.collect_unemployment_data()
        all_data.extend(unemployment_data)

        # 3. GDP ë°ì´í„°
        gdp_data = self.collect_gdp_data()
        all_data.extend(gdp_data)

        # 4. FOMC ì¼ì •
        fomc_data = self.collect_fomc_calendar()

        # 5. ì‹œê·¸ë„ ë¶„ì„
        logger.info("\nğŸ“Š ì‹œê·¸ë„ ë¶„ì„ ì¤‘...")
        signals = []
        for data_point in all_data:
            signal = self.analyze_macro_signal(data_point)
            if signal.get("signal"):
                signals.append(signal)
                logger.info(f"  ğŸ“ˆ {signal['indicator']}: {signal['signal']}")

        # 6. ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
        if all_data:
            self.save_to_database(all_data)

        logger.info("\n" + "=" * 60)
        logger.success(f"âœ… ê±°ì‹œê²½ì œ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {len(all_data)}ê°œ")
        logger.success(f"âœ… ì‹œê·¸ë„ ë°œê²¬: {len(signals)}ê°œ")
        logger.info("=" * 60)

        return {
            "data": all_data,
            "signals": signals,
            "fomc_calendar": fomc_data
        }


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    collector = MacroNewsCollector()
    result = collector.run()

    # ê²°ê³¼ ì¶œë ¥
    if result["signals"]:
        logger.info("\nğŸ¯ ë°œê²¬ëœ ì‹œê·¸ë„:")
        for signal in result["signals"]:
            logger.info(f"  - {signal['indicator']}: {signal['signal']}")
            logger.info(f"    ì˜í–¥ ì„¹í„°: {', '.join(signal['affected_sectors'])}")
            logger.info(f"    ì˜í–¥ë„: {signal['impact_level']}\n")


if __name__ == "__main__":
    main()
