#!/usr/bin/env python3
"""
ìƒˆë¡œìš´ ì›Œí¬í”Œë¡œìš°: ë‹¤ìš´ë¡œë“œ â†’ í¬ë¡­ â†’ ì„ ì • â†’ Supabase ì €ì¥
1. Midjourney ì´ë¯¸ì§€ ìƒì„± (ë¡œì»¬ ë‹¤ìš´ë¡œë“œë§Œ)
2. ë¡œì»¬ì—ì„œ 4ê°œ í¬ë¡­ ìƒì„±
3. AIê°€ ìµœê³  í¬ë¡­ ì„ ì •
4. ì›ë³¸ + ì„ ì •ëœ í¬ë¡­ë§Œ Supabaseì— ì €ì¥
"""
import os
import sys
import json
import requests
from pathlib import Path
from typing import Dict, List, Tuple
from PIL import Image

# magic_book ëª¨ë“ˆ import
magic_book_path = Path.home() / 'dev' / 'magic_book'
sys.path.insert(0, str(magic_book_path))

from dotenv import load_dotenv
from supabase import create_client
from loguru import logger
from src.midjourney.client import PassPromptToSelfBot, wait_for_image_completion, download_image
from src.midjourney.processor import crop_image_cross
from src.midjourney.storage import MidjourneyImageStorage

env_path = Path(__file__).parent.parent / '.env'
load_dotenv(env_path)

supabase_url = os.getenv("SUPABASE_URL")
supabase_key = os.getenv("SUPABASE_KEY")

# ê° ë¸”ë¡œê·¸ ê¸°ì‚¬ë³„ 5ì¥ì˜ ì´ë¯¸ì§€ ì™„ì „ ë§¤í•‘
COMPLETE_ARTICLE_IMAGE_MAPPING = {
    "article_NVDA_blackwell_gpu_20251113.md": [
        {"key": "NVDA_blackwell_chip", "num": 1},
        {"key": "NVDA_ai_datacenter", "num": 2},
        {"key": "NVDA_blackwell_chip", "num": 3},
        {"key": "NVDA_ai_datacenter", "num": 4},
        {"key": "NVDA_blackwell_chip", "num": 5}
    ],
    "article_NVDA_foxconn_ai_server_20251115.md": [
        {"key": "NVDA_blackwell_chip", "num": 1},
        {"key": "NVDA_ai_datacenter", "num": 2},
        {"key": "NVDA_blackwell_chip", "num": 3},
        {"key": "NVDA_ai_datacenter", "num": 4},
        {"key": "NVDA_blackwell_chip", "num": 5}
    ],
    "article_TSLA_robotaxi_fleet_20251113.md": [
        {"key": "TSLA_robotaxi", "num": 1},
        {"key": "TSLA_charging_network", "num": 2},
        {"key": "TSLA_robotaxi", "num": 3},
        {"key": "TSLA_charging_network", "num": 4},
        {"key": "TSLA_robotaxi", "num": 5}
    ],
    "article_AAPL_iphone_sales_20251113.md": [
        {"key": "AAPL_premium_iphone", "num": 1},
        {"key": "AAPL_enterprise", "num": 2},
        {"key": "AAPL_premium_iphone", "num": 3},
        {"key": "AAPL_enterprise", "num": 4},
        {"key": "AAPL_premium_iphone", "num": 5}
    ],
    "article_ADBE_creative_ai_20251113.md": [
        {"key": "ADBE_creative_cloud", "num": 1},
        {"key": "ADBE_firefly_ai", "num": 2},
        {"key": "ADBE_creative_cloud", "num": 3},
        {"key": "ADBE_firefly_ai", "num": 4},
        {"key": "ADBE_creative_cloud", "num": 5}
    ],
    "article_AMZN_aws_ai_services_20251113.md": [
        {"key": "AMZN_aws_cloud", "num": 1},
        {"key": "AMZN_ai_services", "num": 2},
        {"key": "AMZN_aws_cloud", "num": 3},
        {"key": "AMZN_ai_services", "num": 4},
        {"key": "AMZN_aws_cloud", "num": 5}
    ],
    "article_GOOGL_search_ai_20251113.md": [
        {"key": "GOOGL_search_ai", "num": 1},
        {"key": "GOOGL_advertising", "num": 2},
        {"key": "GOOGL_search_ai", "num": 3},
        {"key": "GOOGL_advertising", "num": 4},
        {"key": "GOOGL_search_ai", "num": 5}
    ],
    "article_META_enterprise_ai_20251113.md": [
        {"key": "META_business_ai", "num": 1},
        {"key": "META_llama_opensource", "num": 2},
        {"key": "META_business_ai", "num": 3},
        {"key": "META_llama_opensource", "num": 4},
        {"key": "META_business_ai", "num": 5}
    ],
    "article_MSFT_AI_office_integration_20251113.md": [
        {"key": "MSFT_copilot", "num": 1},
        {"key": "MSFT_azure_cloud", "num": 2},
        {"key": "MSFT_copilot", "num": 3},
        {"key": "MSFT_azure_cloud", "num": 4},
        {"key": "MSFT_copilot", "num": 5}
    ],
    "article_NFLX_subscriber_growth_20251113.md": [
        {"key": "NFLX_streaming", "num": 1},
        {"key": "NFLX_advertising", "num": 2},
        {"key": "NFLX_streaming", "num": 3},
        {"key": "NFLX_advertising", "num": 4},
        {"key": "NFLX_streaming", "num": 5}
    ],
    "article_UBER_profitability_expansion_20251113.md": [
        {"key": "UBER_rideshare", "num": 1},
        {"key": "UBER_eats", "num": 2},
        {"key": "UBER_rideshare", "num": 3},
        {"key": "UBER_eats", "num": 4},
        {"key": "UBER_rideshare", "num": 5}
    ]
}

def load_prompts() -> Dict:
    """AI ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ë¡œë“œ"""
    prompt_file = Path(__file__).parent / 'ai_image_prompts.json'
    with open(prompt_file, 'r', encoding='utf-8') as f:
        return json.load(f)

def generate_midjourney_image(prompt: str, timeout: int = 300) -> str:
    """
    Midjourney ì´ë¯¸ì§€ ìƒì„± ë° URL ë°˜í™˜ (Supabase ì €ì¥ ì—†ìŒ)

    Returns:
        ì´ë¯¸ì§€ URL
    """
    import time

    logger.info(f"ğŸ“¤ í”„ë¡¬í”„íŠ¸ ì „ì†¡: {prompt[:60]}...")
    request_timestamp = time.time()
    response = PassPromptToSelfBot(prompt)

    if response.status_code != 204:
        logger.error(f"âŒ ì´ë¯¸ì§€ ìƒì„± ìš”ì²­ ì‹¤íŒ¨: HTTP {response.status_code}")
        return None

    logger.info("â³ ì´ë¯¸ì§€ ì™„ì„± ëŒ€ê¸° ì¤‘...")
    image_urls = wait_for_image_completion(
        prompt=prompt,
        request_timestamp=request_timestamp,
        timeout=timeout,
        check_interval=5
    )

    if not image_urls:
        logger.error("âŒ ì´ë¯¸ì§€ ìƒì„± íƒ€ì„ì•„ì›ƒ")
        return None

    return image_urls[0]  # ì²«ë²ˆì§¸ ì´ë¯¸ì§€ URL ë°˜í™˜

def download_and_crop_locally(image_url: str, save_dir: Path) -> Tuple[Path, List[Path]]:
    """
    ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë° ë¡œì»¬ í¬ë¡­

    Returns:
        (ì›ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ, í¬ë¡­ ì´ë¯¸ì§€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸)
    """
    # ì›ë³¸ ë‹¤ìš´ë¡œë“œ
    save_dir.mkdir(parents=True, exist_ok=True)
    original_path = save_dir / "original.jpg"

    logger.info(f"ğŸ“¥ ì›ë³¸ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì¤‘...")
    response = requests.get(image_url)
    response.raise_for_status()

    with open(original_path, 'wb') as f:
        f.write(response.content)
    logger.success(f"âœ… ì›ë³¸ ì €ì¥: {original_path}")

    # 4ê°œ í¬ë¡­ ìƒì„± (ì‹­ì 4ë“±ë¶„)
    logger.info(f"âœ‚ï¸  4ê°œ í¬ë¡­ ìƒì„± ì¤‘ (ì‹­ì 4ë“±ë¶„)...")
    crop_paths_str = crop_image_cross(
        image_path=str(original_path),
        output_dir=str(save_dir)
    )

    # ë¬¸ìì—´ ê²½ë¡œë¥¼ Path ê°ì²´ë¡œ ë³€í™˜
    crop_paths = [Path(p) for p in crop_paths_str]

    logger.success(f"âœ… í¬ë¡­ ì™„ë£Œ: {len(crop_paths)}ê°œ")
    crop_names = ['top_left', 'top_right', 'bottom_left', 'bottom_right']
    for idx, crop_path in enumerate(crop_paths):
        logger.info(f"   â€¢ {crop_names[idx]}: {crop_path.name}")

    return original_path, crop_paths

def select_best_crop_ai(crop_paths: List[Path], prompt: str) -> Path:
    """
    AIê°€ ìµœê³  í¬ë¡­ ì„ ì • (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹± ì‚¬ìš©)

    ì‹¤ì œë¡œëŠ” Claude Vision APIë‚˜ GPT-4Vë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆì§€ë§Œ,
    ì§€ê¸ˆì€ ê°„ë‹¨í•˜ê²Œ top_leftë¥¼ ê¸°ë³¸ìœ¼ë¡œ ì„ íƒ
    """
    # TODO: Claude Vision APIë‚˜ GPT-4Vë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ AI ì„ ì • êµ¬í˜„
    # í˜„ì¬ëŠ” ì²«ë²ˆì§¸ í¬ë¡­ (top_left) ì„ íƒ
    best_crop = crop_paths[0]
    logger.info(f"ğŸ¤– AI ì„ ì • í¬ë¡­: {best_crop.name}")
    return best_crop

def upload_to_supabase(
    best_crop_path: Path,
    prompt: str
):
    """
    ì„ ì •ëœ í¬ë¡­ë§Œ Supabaseì— ì—…ë¡œë“œ (ì›ë³¸ì€ ë¡œì»¬ì—ë§Œ ì €ì¥)
    """
    storage = MidjourneyImageStorage()

    # ì„ ì •ëœ í¬ë¡­ë§Œ ì—…ë¡œë“œ
    logger.info(f"â˜ï¸  ì„ ì • í¬ë¡­ Supabase ì—…ë¡œë“œ ì¤‘...")

    crop_result = storage.save_midjourney_image(
        image_path=str(best_crop_path),
        prompt=prompt,
        auto_crop=False,
        metadata={'crop_position': best_crop_path.stem, 'is_selected_crop': True}
    )

    if not crop_result.get('success'):
        logger.error(f"âŒ í¬ë¡­ ì—…ë¡œë“œ ì‹¤íŒ¨: {crop_result.get('error')}")
        return None

    crop_id = crop_result['image_id']
    crop_url = crop_result['original_url']
    logger.success(f"âœ… í¬ë¡­ ì—…ë¡œë“œ ì™„ë£Œ!")
    logger.info(f"   Crop ID: {crop_id}")
    logger.info(f"   URL: {crop_url[:60]}...")

    return {
        'crop_id': crop_id,
        'crop_url': crop_url
    }

def main():
    logger.info("=" * 80)
    logger.info("ğŸ”„ ìƒˆë¡œìš´ ì›Œí¬í”Œë¡œìš°: ë‹¤ìš´ë¡œë“œ â†’ í¬ë¡­ â†’ ì„ ì • â†’ Supabase ì €ì¥")
    logger.info("=" * 80)

    # í”„ë¡¬í”„íŠ¸ ë¡œë“œ
    prompts_data = load_prompts()
    logger.info(f"ğŸ“ ë¡œë“œëœ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿: {len(prompts_data)}ê°œ")

    # í•„ìš”í•œ ê³ ìœ  í‚¤ ì¶”ì¶œ
    unique_keys = set()
    for article, images in COMPLETE_ARTICLE_IMAGE_MAPPING.items():
        for img in images:
            unique_keys.add(img['key'])

    logger.info(f"\nğŸ”‘ í•„ìš”í•œ ê³ ìœ  ì´ë¯¸ì§€ í‚¤: {len(unique_keys)}ê°œ")
    logger.info(f"   {', '.join(sorted(unique_keys))}")

    # ê° í‚¤ë³„ë¡œ í•„ìš”í•œ ê°œìˆ˜ ê³„ì‚°
    key_needs = {}
    for article, images in COMPLETE_ARTICLE_IMAGE_MAPPING.items():
        for img in images:
            key = img['key']
            key_needs[key] = key_needs.get(key, 0) + 1

    logger.info(f"\nğŸ“‹ í‚¤ë³„ í•„ìš” ì´ë¯¸ì§€ ê°œìˆ˜:")
    for key, count in sorted(key_needs.items()):
        logger.info(f"   â€¢ {key}: {count}ê°œ")

    # ì‘ì—… ë””ë ‰í† ë¦¬ ìƒì„±
    work_dir = Path(__file__).parent.parent / 'temp_images'
    work_dir.mkdir(parents=True, exist_ok=True)

    # ê° í‚¤ë³„ë¡œ ì´ë¯¸ì§€ ìƒì„±
    logger.info(f"\nğŸ¨ ì´ë¯¸ì§€ ìƒì„± ì‹œì‘...")

    results = {}
    sorted_keys = sorted(key_needs.items(), key=lambda x: x[1], reverse=True)

    for idx, (key, needed_count) in enumerate(sorted_keys, 1):
        logger.info(f"\n{'='*80}")
        logger.info(f"[{idx}/{len(sorted_keys)}] ì²˜ë¦¬ ì¤‘: {key} (í•„ìš”: {needed_count}ê°œ)")
        logger.info(f"{'='*80}")

        if key not in prompts_data:
            logger.warning(f"âš ï¸  í”„ë¡¬í”„íŠ¸ ì—†ìŒ: {key}")
            continue

        prompt = prompts_data[key]['midjourney_prompt']

        # í•„ìš”í•œ ë§Œí¼ë§Œ ìƒì„± (ìµœëŒ€ 3ê°œ)
        for i in range(min(needed_count, 3)):
            logger.info(f"\nğŸ¯ {key} - {i+1}/{min(needed_count, 3)}")

            try:
                # 1. Midjourney ì´ë¯¸ì§€ ìƒì„±
                image_url = generate_midjourney_image(prompt, timeout=300)
                if not image_url:
                    logger.error(f"âŒ ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨")
                    continue

                # 2. ë¡œì»¬ ë‹¤ìš´ë¡œë“œ + í¬ë¡­
                key_dir = work_dir / f"{key}_{i+1}"
                original_path, crop_paths = download_and_crop_locally(image_url, key_dir)

                # 3. AI ìµœê³  í¬ë¡­ ì„ ì •
                best_crop = select_best_crop_ai(crop_paths, prompt)

                # 4. Supabase ì—…ë¡œë“œ (ì„ ì •ëœ í¬ë¡­ë§Œ)
                upload_result = upload_to_supabase(best_crop, prompt)

                if upload_result:
                    if key not in results:
                        results[key] = []
                    results[key].append(upload_result)
                    logger.success(f"âœ… ì™„ë£Œ!")
                else:
                    logger.error(f"âŒ ì—…ë¡œë“œ ì‹¤íŒ¨")

            except Exception as e:
                logger.error(f"âŒ ì˜¤ë¥˜: {e}")
                continue

    # ê²°ê³¼ ìš”ì•½
    logger.info("\n" + "=" * 80)
    logger.success("âœ… ì „ì²´ ì‘ì—… ì™„ë£Œ!")
    logger.info("=" * 80)
    logger.info(f"\nğŸ“Š ê²°ê³¼ ìš”ì•½:")
    for key, key_results in results.items():
        logger.info(f"   â€¢ {key}: {len(key_results)}ê°œ ìƒì„±")

    logger.info(f"\nğŸ“ ì„ì‹œ íŒŒì¼ ìœ„ì¹˜: {work_dir}")
    logger.info(f"ğŸ’¡ ë‹¤ìŒ ë‹¨ê³„: download_and_place_images.py ì‹¤í–‰í•˜ì—¬ ë¸”ë¡œê·¸ì— ë°°ì¹˜")

if __name__ == "__main__":
    main()
