#!/usr/bin/env python3
"""
ë¯¸ë“œì €ë‹ˆ í¬ë¡­ëœ ì´ë¯¸ì§€ í™•ì¸ ë° blog_images ì—…ë°ì´íŠ¸
"""
import os
from dotenv import load_dotenv
from loguru import logger
from supabase import create_client

load_dotenv()

def check_and_fix_cropped_images():
    """í¬ë¡­ëœ ì´ë¯¸ì§€ í™•ì¸ ë° images í…Œì´ë¸” ì—…ë°ì´íŠ¸"""

    supabase_url = os.getenv("SUPABASE_URL")
    supabase_key = os.getenv("SUPABASE_KEY")

    if not supabase_url or not supabase_key:
        logger.error("âŒ SUPABASE_URL/KEY ì„¤ì • ëˆ„ë½")
        return False

    supabase = create_client(supabase_url, supabase_key)

    logger.info("=" * 60)
    logger.info("ğŸ” í¬ë¡­ëœ ì´ë¯¸ì§€ í™•ì¸ ë° ìˆ˜ì •")
    logger.info("=" * 60)

    # 1ë‹¨ê³„: í˜„ì¬ blog_imagesì— ì—°ê²°ëœ original ì´ë¯¸ì§€ í™•ì¸
    logger.info("\nğŸ“ 1ë‹¨ê³„: í˜„ì¬ blog_images ì—°ê²° ìƒíƒœ í™•ì¸ ì¤‘...")

    try:
        blog_result = supabase.table('blog_images') \
            .select('*, images(*)') \
            .eq('article_id', 'nvda_blackwell_20251113') \
            .order('position') \
            .execute()

        if not blog_result.data:
            logger.error("âŒ blog_images í…Œì´ë¸”ì´ ë¹„ì–´ìˆìŒ")
            return False

        logger.info(f"  âœ… {len(blog_result.data)}ê°œ ì´ë¯¸ì§€ ì—°ê²°ë¨")

        current_images = []
        for record in blog_result.data:
            img = record.get('images', {})
            img_url = img.get('image_url', '')
            logger.info(f"  Position {record.get('position')}: {img_url[:80]}...")

            # /originals/ ê²½ë¡œì—ì„œ íŒŒì¼ëª… ì¶”ì¶œ
            if '/originals/' in img_url:
                filename = img_url.split('/originals/')[-1]
                current_images.append({
                    'position': record.get('position'),
                    'image_id': record.get('image_id'),
                    'original_url': img_url,
                    'original_filename': filename
                })
                logger.warning(f"       âš ï¸  ORIGINAL ì´ë¯¸ì§€ (í¬ë¡­ ì „)")

    except Exception as e:
        logger.error(f"âŒ blog_images ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return False

    # 2ë‹¨ê³„: midjourney_imagesì—ì„œ í¬ë¡­ëœ ë²„ì „ ì°¾ê¸°
    logger.info("\nğŸ“ 2ë‹¨ê³„: í¬ë¡­ëœ ì´ë¯¸ì§€ ê²€ìƒ‰ ì¤‘...")

    cropped_mapping = {}

    for img_info in current_images:
        try:
            # ì›ë³¸ íŒŒì¼ëª…ìœ¼ë¡œ midjourney_imagesì—ì„œ original ë ˆì½”ë“œ ì°¾ê¸°
            original_result = supabase.table('midjourney_images') \
                .select('*') \
                .eq('image_type', 'original') \
                .ilike('public_url', f'%{img_info["original_filename"]}') \
                .execute()

            if not original_result.data:
                logger.warning(f"  âš ï¸  Position {img_info['position']}: midjourney_imagesì—ì„œ original ë ˆì½”ë“œ ëª» ì°¾ìŒ")
                continue

            original_record = original_result.data[0]
            original_id = original_record.get('id')

            logger.info(f"  Position {img_info['position']}: Original ID = {original_id}")

            # ì´ original_idì˜ image_idë¥¼ parent_image_idë¡œ ê°–ëŠ” cropped ì´ë¯¸ì§€ ì°¾ê¸°
            original_image_id = original_record.get('image_id')  # ì˜ˆ: "f5abc6f2b048"

            cropped_result = supabase.table('midjourney_images') \
                .select('*') \
                .eq('image_type', 'cropped') \
                .eq('parent_image_id', original_image_id) \
                .execute()

            if cropped_result.data:
                logger.success(f"       âœ… {len(cropped_result.data)}ê°œ í¬ë¡­ ì´ë¯¸ì§€ ë°œê²¬!")

                # ì²« ë²ˆì§¸ í¬ë¡­ ì´ë¯¸ì§€ ì‚¬ìš© (top_left)
                cropped_img = cropped_result.data[0]
                cropped_url = cropped_img.get('public_url', '')

                cropped_mapping[img_info['position']] = {
                    'image_id': img_info['image_id'],
                    'old_url': img_info['original_url'],
                    'new_url': cropped_url,
                    'cropped_record': cropped_img
                }

                logger.info(f"       NEW: {cropped_url[:80]}...")
            else:
                logger.warning(f"       âš ï¸  í¬ë¡­ ì´ë¯¸ì§€ ì—†ìŒ (parent_id={original_id})")

        except Exception as e:
            logger.error(f"  âŒ Position {img_info['position']} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            continue

    # 3ë‹¨ê³„: images í…Œì´ë¸” ì—…ë°ì´íŠ¸
    logger.info("\nğŸ“ 3ë‹¨ê³„: images í…Œì´ë¸” ì—…ë°ì´íŠ¸ ì¤‘...")

    if not cropped_mapping:
        logger.error("âŒ ì—…ë°ì´íŠ¸í•  í¬ë¡­ ì´ë¯¸ì§€ê°€ ì—†ìŒ")
        return False

    updated_count = 0

    for position, mapping in cropped_mapping.items():
        try:
            update_result = supabase.table('images') \
                .update({'image_url': mapping['new_url']}) \
                .eq('id', mapping['image_id']) \
                .execute()

            if update_result.data:
                logger.success(f"  âœ… Position {position}: images í…Œì´ë¸” ì—…ë°ì´íŠ¸ ì™„ë£Œ")
                logger.info(f"     OLD: {mapping['old_url'][:70]}...")
                logger.info(f"     NEW: {mapping['new_url'][:70]}...")
                updated_count += 1
            else:
                logger.error(f"  âŒ Position {position}: ì—…ë°ì´íŠ¸ ì‹¤íŒ¨")

        except Exception as e:
            logger.error(f"  âŒ Position {position} ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            continue

    # 4ë‹¨ê³„: ê²€ì¦
    logger.info("\nğŸ“ 4ë‹¨ê³„: ì—…ë°ì´íŠ¸ ê²°ê³¼ ê²€ì¦ ì¤‘...")

    try:
        verify_result = supabase.table('blog_images') \
            .select('*, images(*)') \
            .eq('article_id', 'nvda_blackwell_20251113') \
            .order('position') \
            .execute()

        if verify_result.data:
            logger.success(f"\nâœ… ê²€ì¦ ì™„ë£Œ! {len(verify_result.data)}ê°œ ì´ë¯¸ì§€ í™•ì¸")
            logger.info("\nì—…ë°ì´íŠ¸ëœ ì´ë¯¸ì§€:")

            for record in verify_result.data:
                img = record.get('images', {})
                img_url = img.get('image_url', '')

                if '/cropped/' in img_url:
                    logger.success(f"  Position {record.get('position')}: âœ… CROPPED - {img_url[:70]}...")
                elif '/originals/' in img_url:
                    logger.warning(f"  Position {record.get('position')}: âš ï¸  ORIGINAL - {img_url[:70]}...")
                else:
                    logger.info(f"  Position {record.get('position')}: {img_url[:70]}...")

            return True
        else:
            logger.error("âŒ blog_images í…Œì´ë¸”ì´ ë¹„ì–´ìˆìŒ")
            return False

    except Exception as e:
        logger.error(f"âŒ ê²€ì¦ ì‹¤íŒ¨: {e}")
        return False


if __name__ == "__main__":
    success = check_and_fix_cropped_images()

    if success:
        logger.success("\n" + "=" * 60)
        logger.success("ğŸ‰ í¬ë¡­ëœ ì´ë¯¸ì§€ë¡œ ì—…ë°ì´íŠ¸ ì™„ë£Œ!")
        logger.success("==" * 60)
        logger.info("\në‹¤ìŒ ë‹¨ê³„:")
        logger.info("1. ë¡œì»¬ì—ì„œ HTML í™•ì¸: file:///Users/jinxin/dev/aivesto/public/articles/article_NVDA_blackwell_gpu_20251113.html")
        logger.info("2. GitHub ì»¤ë°‹ ë° í‘¸ì‹œ")
        logger.info("3. Vercel ìë™ ë°°í¬ í™•ì¸")
    else:
        logger.error("\n" + "=" * 60)
        logger.error("âŒ í¬ë¡­ ì´ë¯¸ì§€ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨")
        logger.error("=" * 60)
