#!/usr/bin/env python3
"""
ë¸”ë¡œê·¸ ê¸°ì‚¬ë‹¹ 5ì¥ ì´ìƒì˜ ì´ë¯¸ì§€ ìƒì„±
ë¶€ì¡±í•œ ì´ë¯¸ì§€ë“¤ì„ ì¶”ê°€ë¡œ ìƒì„±
"""
import os
import sys
import json
import requests
from pathlib import Path
from typing import Dict, List

# magic_book ëª¨ë“ˆ import
magic_book_path = Path.home() / 'dev' / 'magic_book'
sys.path.insert(0, str(magic_book_path))

from dotenv import load_dotenv
from supabase import create_client
from loguru import logger
from src.midjourney import generate_images_batch_and_save

env_path = Path(__file__).parent.parent / '.env'
load_dotenv(env_path)

supabase_url = os.getenv("SUPABASE_URL")
supabase_key = os.getenv("SUPABASE_KEY")

# ê° ë¸”ë¡œê·¸ ê¸°ì‚¬ë³„ 5ì¥ì˜ ì´ë¯¸ì§€ ì™„ì „ ë§¤í•‘
COMPLETE_ARTICLE_IMAGE_MAPPING = {
    "article_NVDA_blackwell_gpu_20251113.md": [
        {"key": "NVDA_blackwell_chip", "num": 1},
        {"key": "NVDA_ai_datacenter", "num": 2},
        {"key": "NVDA_blackwell_chip", "num": 3},  # ë‹¤ë¥¸ ì•µê¸€
        {"key": "NVDA_ai_datacenter", "num": 4},   # ë‹¤ë¥¸ ì•µê¸€
        {"key": "NVDA_blackwell_chip", "num": 5}   # ë‹¤ë¥¸ ì•µê¸€
    ],
    "article_NVDA_foxconn_ai_server_20251115.md": [
        {"key": "NVDA_blackwell_chip", "num": 1},
        {"key": "NVDA_ai_datacenter", "num": 2},
        {"key": "NVDA_blackwell_chip", "num": 3},
        {"key": "NVDA_ai_datacenter", "num": 4},
        {"key": "NVDA_blackwell_chip", "num": 5}
    ],
    "article_TSLA_robotaxi_fleet_20251113.md": [
        {"key": "TSLA_robotaxi", "num": 1},
        {"key": "TSLA_charging_network", "num": 2},
        {"key": "TSLA_robotaxi", "num": 3},
        {"key": "TSLA_charging_network", "num": 4},
        {"key": "TSLA_robotaxi", "num": 5}
    ],
    "article_AAPL_iphone_sales_20251113.md": [
        {"key": "AAPL_premium_iphone", "num": 1},
        {"key": "AAPL_enterprise", "num": 2},
        {"key": "AAPL_premium_iphone", "num": 3},
        {"key": "AAPL_enterprise", "num": 4},
        {"key": "AAPL_premium_iphone", "num": 5}
    ],
    "article_ADBE_creative_ai_20251113.md": [
        {"key": "ADBE_creative_cloud", "num": 1},
        {"key": "ADBE_firefly_ai", "num": 2},
        {"key": "ADBE_creative_cloud", "num": 3},
        {"key": "ADBE_firefly_ai", "num": 4},
        {"key": "ADBE_creative_cloud", "num": 5}
    ],
    "article_AMZN_aws_ai_services_20251113.md": [
        {"key": "AMZN_aws_cloud", "num": 1},
        {"key": "AMZN_ai_services", "num": 2},
        {"key": "AMZN_aws_cloud", "num": 3},
        {"key": "AMZN_ai_services", "num": 4},
        {"key": "AMZN_aws_cloud", "num": 5}
    ],
    "article_GOOGL_search_ai_20251113.md": [
        {"key": "GOOGL_search_ai", "num": 1},
        {"key": "GOOGL_advertising", "num": 2},
        {"key": "GOOGL_search_ai", "num": 3},
        {"key": "GOOGL_advertising", "num": 4},
        {"key": "GOOGL_search_ai", "num": 5}
    ],
    "article_META_enterprise_ai_20251113.md": [
        {"key": "META_business_ai", "num": 1},
        {"key": "META_llama_opensource", "num": 2},
        {"key": "META_business_ai", "num": 3},
        {"key": "META_llama_opensource", "num": 4},
        {"key": "META_business_ai", "num": 5}
    ],
    "article_MSFT_AI_office_integration_20251113.md": [
        {"key": "MSFT_copilot", "num": 1},
        {"key": "MSFT_azure_cloud", "num": 2},
        {"key": "MSFT_copilot", "num": 3},
        {"key": "MSFT_azure_cloud", "num": 4},
        {"key": "MSFT_copilot", "num": 5}
    ],
    "article_NFLX_subscriber_growth_20251113.md": [
        {"key": "NFLX_streaming", "num": 1},
        {"key": "NFLX_advertising", "num": 2},
        {"key": "NFLX_streaming", "num": 3},
        {"key": "NFLX_advertising", "num": 4},
        {"key": "NFLX_streaming", "num": 5}
    ],
    "article_UBER_profitability_expansion_20251113.md": [
        {"key": "UBER_rideshare", "num": 1},
        {"key": "UBER_eats", "num": 2},
        {"key": "UBER_rideshare", "num": 3},
        {"key": "UBER_eats", "num": 4},
        {"key": "UBER_rideshare", "num": 5}
    ]
}

def load_prompts() -> Dict:
    """AI ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ë¡œë“œ"""
    prompt_file = Path(__file__).parent / 'ai_image_prompts.json'
    with open(prompt_file, 'r', encoding='utf-8') as f:
        return json.load(f)

def get_existing_images_count():
    """Supabaseì— ì´ë¯¸ ìˆëŠ” ì´ë¯¸ì§€ ê°œìˆ˜ í™•ì¸"""
    supabase = create_client(supabase_url, supabase_key)
    result = supabase.table('midjourney_images')\
        .select('*', count='exact')\
        .eq('image_type', 'original')\
        .execute()
    return result.count

def main():
    logger.info("=" * 80)
    logger.info("ğŸ¨ ë¸”ë¡œê·¸ ê¸°ì‚¬ë‹¹ 5ì¥ ì´ë¯¸ì§€ ìƒì„±")
    logger.info("=" * 80)

    # ê¸°ì¡´ ì´ë¯¸ì§€ í™•ì¸
    existing_count = get_existing_images_count()
    logger.info(f"\nğŸ“Š í˜„ì¬ Supabaseì— ì €ì¥ëœ ì›ë³¸ ì´ë¯¸ì§€: {existing_count}ê°œ")

    # í”„ë¡¬í”„íŠ¸ ë¡œë“œ
    prompts_data = load_prompts()
    logger.info(f"ğŸ“ ë¡œë“œëœ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿: {len(prompts_data)}ê°œ")

    # í•„ìš”í•œ ê³ ìœ  í‚¤ ì¶”ì¶œ
    unique_keys = set()
    for article, images in COMPLETE_ARTICLE_IMAGE_MAPPING.items():
        for img in images:
            unique_keys.add(img['key'])

    logger.info(f"\nğŸ”‘ í•„ìš”í•œ ê³ ìœ  ì´ë¯¸ì§€ í‚¤: {len(unique_keys)}ê°œ")
    logger.info(f"   {', '.join(sorted(unique_keys))}")

    # ê° í‚¤ë³„ë¡œ í•„ìš”í•œ ê°œìˆ˜ ê³„ì‚°
    key_needs = {}
    for article, images in COMPLETE_ARTICLE_IMAGE_MAPPING.items():
        for img in images:
            key = img['key']
            key_needs[key] = key_needs.get(key, 0) + 1

    logger.info(f"\nğŸ“‹ í‚¤ë³„ í•„ìš” ì´ë¯¸ì§€ ê°œìˆ˜:")
    for key, count in sorted(key_needs.items()):
        logger.info(f"   â€¢ {key}: {count}ê°œ")

    # ì´ í•„ìš” ì´ë¯¸ì§€ ê³„ì‚°
    total_needed = sum(key_needs.values())
    logger.info(f"\nğŸ“Š ì´ê³„:")
    logger.info(f"   â€¢ ë¸”ë¡œê·¸ ê¸°ì‚¬: {len(COMPLETE_ARTICLE_IMAGE_MAPPING)}ê°œ")
    logger.info(f"   â€¢ ê¸°ì‚¬ë‹¹ ì´ë¯¸ì§€: 5ì¥")
    logger.info(f"   â€¢ ì´ í•„ìš” ì´ë¯¸ì§€: {total_needed}ê°œ")
    logger.info(f"   â€¢ ì´ë¯¸ ìƒì„±ë¨: {existing_count}ê°œ")
    logger.info(f"   â€¢ ì¶”ê°€ ìƒì„± í•„ìš”: {max(0, total_needed - existing_count)}ê°œ")

    # Midjourney í”„ë¡¬í”„íŠ¸ ì¤€ë¹„ (ê°€ì¥ ë§ì´ í•„ìš”í•œ ìˆœì„œëŒ€ë¡œ)
    sorted_keys = sorted(key_needs.items(), key=lambda x: x[1], reverse=True)

    midjourney_prompts = []
    for key, needed_count in sorted_keys:
        if key in prompts_data:
            prompt = prompts_data[key]['midjourney_prompt']
            # í•„ìš”í•œ ë§Œí¼ í”„ë¡¬í”„íŠ¸ ì¶”ê°€ (ìµœëŒ€ ê° 3ê°œê¹Œì§€)
            for i in range(min(needed_count, 3)):
                midjourney_prompts.append(prompt)
                logger.info(f"   â€¢ {key} ({i+1}/{needed_count}): {prompt[:60]}...")
        else:
            logger.warning(f"   âš ï¸  í”„ë¡¬í”„íŠ¸ ì—†ìŒ: {key}")

    logger.info(f"\nğŸ¨ ìƒì„±í•  Midjourney ì´ë¯¸ì§€: {len(midjourney_prompts)}ê°œ")
    logger.info(f"â±ï¸  ì˜ˆìƒ ì†Œìš” ì‹œê°„: {len(midjourney_prompts) * 1.5:.0f}ë¶„")

    # Midjourney ì´ë¯¸ì§€ ìƒì„±
    logger.info(f"\nâ³ ì´ë¯¸ì§€ ìƒì„± ì‹œì‘...")
    results = generate_images_batch_and_save(
        prompts=midjourney_prompts,
        auto_crop=True,  # 4ê°œ í¬ë¡­ ìƒì„±
        save_locally=False,
        verbose=True
    )

    logger.success(f"\nâœ… ìƒì„± ì™„ë£Œ: {len(results)}ê°œ")

    # ê²°ê³¼ ìš”ì•½
    success_count = sum(1 for r in results if r.success)
    logger.info("\n" + "=" * 80)
    logger.success(f"âœ… ì„±ê³µ: {success_count}/{len(results)}ê°œ")
    logger.info("=" * 80)
    logger.info("\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„: download_and_place_images.py ì‹¤í–‰í•˜ì—¬ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ")

if __name__ == "__main__":
    main()
